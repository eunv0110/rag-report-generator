[
  {
    "page_id": "23da296c-8853-8003-b94f-ed0a1e223920",
    "title": "테니스 모멘텀 계산 및 시각화 결과",
    "created_time": "2025-07-27T08:47:00.000Z",
    "last_edited_time": "2025-12-14T08:40:00.000Z",
    "properties": {
      "유형": "프로젝트현황",
      "생성 일시": "2025-07-27T08:47:00.000Z",
      "날짜": {
        "start": "2025-07-22",
        "end": null
      },
      "최종 편집 일시": "2025-12-14T08:40:00.000Z",
      "이름": "테니스 모멘텀 계산 및 시각화 결과"
    },
    "content": "# 테니스 모멘텀 프로젝트\n### 목표\n• 논문의 HMM + EMA 모멘텀 계산 알고리즘 재현\n• 테니스 경기 흐름(모멘텀) 실시간 시각화\n• 변수 중요도 분석 및 상관관계 히트맵 생성\n• 참고 논문 : Capturing Momentum: Tennis Match Analysis Using Machine Learning and Time Series Theory\n1. HMM (Hidden Markov Model): 숨겨진 모멘텀 상태 추정\n1. EMA (Exponential Moving Average): 모멘텀 값 부드럽게 처리\n1. 1단계: HMM 학습 → 2단계: EMA 적용\n### 처리 결과\n• 성공: 6,605개 경기 모멘텀 계산 완료\n• 일부 수렴 실패: \"Model is not converging\" (정상적인 현상)\n• 최종 범위: 모멘텀 값 -2 ~ +2\n## 시각화 결과\n[Image: notion_images/23da296c-8853-8003-b94f-ed0a1e223920_23da296c-8853-8058-a62a-ef5fb9a5d56c.png]\n• X축: 포인트 번호 (시간 흐름)\n• Y축: 모멘텀 (-2 ~ +2)\n• 빨간점: Player 1 승리 포인트\n• 파란점: Player 2 승리 포인트\n### 전체 데이터 히트맵\n[Image: notion_images/23da296c-8853-8003-b94f-ed0a1e223920_23da296c-8853-804d-b575-d40c98e731fd.png]\n•  문제: 6천개 경기를 평균내서 개별 패턴 소실\n• 결과: 모멘텀과 모든 변수가 음의 상관관계 (-0.29 ~ -0.22)\n### 개별 경기 히트맵\n[Image: notion_images/23da296c-8853-8003-b94f-ed0a1e223920_23da296c-8853-801e-a4bb-e9625b3bf411.png]\n• 해결책: 특정 경기만 선택해서 분석\n• 기대 결과: 모멘텀 ↔ 승리확률 강한 상관관계\n## 주요 성과\n• HMM + EMA 알고리즘 구현 완료\n• 동일한 모멘텀 범위 (-2 ~ +2) 달성\n## 최종 결론\n• 프로젝트 성공\n> 논문의 핵심 알고리즘인 HMM + EMA 기반 테니스 모멘텀 계산을 성공적으로 재현\n  특히 개별 경기의 모멘텀 시각화에서 성공적인 수준 결과를 달성하여,\n테니스 경기 흐름 분석의 실용적 도구로 활용 가능\n### 핵심 인사이트\n• 경기 중 흐름 변화를 수치로 포착 가능\n• 실시간 분석의 중요성: Data Leakage 방지가 모델 신뢰성의 핵심\n• 개별 vs 전체: 평균화된 분석보다 개별 경기 분석이 더 의미있음\n# 다음 단계\n• 여자 경기 데이터 적용"
  },
  {
    "page_id": "23da296c-8853-8030-87ef-cf9e7913bf81",
    "title": "줄넘기 수집데이터 전처리 2차",
    "created_time": "2025-07-27T08:50:00.000Z",
    "last_edited_time": "2025-07-27T08:50:00.000Z",
    "properties": {
      "유형": "프로젝트현황",
      "생성 일시": "2025-07-27T08:50:00.000Z",
      "날짜": {
        "start": "2025-07-14",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:50:00.000Z",
      "이름": "줄넘기 수집데이터 전처리 2차"
    },
    "content": "• 34개 영상 전처리 진행\n남은 영상\n• 2단뛰기 영상 2개\n• x자 29개\n• 번갈아뛰기 24개"
  },
  {
    "page_id": "23da296c-8853-8053-a4eb-fee798646b20",
    "title": "테니스 모멘텀 데이터 전처리",
    "created_time": "2025-07-27T08:48:00.000Z",
    "last_edited_time": "2025-07-27T08:49:00.000Z",
    "properties": {
      "유형": "자료조사",
      "생성 일시": "2025-07-27T08:48:00.000Z",
      "날짜": {
        "start": "2025-07-21",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:49:00.000Z",
      "이름": "테니스 모멘텀 데이터 전처리"
    },
    "content": "# 데이터 정보\n## 기본 경기 정보\n• match_id: 고유한 경기 식별자\n• Pt: 경기 내 포인트 번호 (1부터 시작)\n• Set1/Set2: Player1/Player2가 현재까지 획득한 세트 수\n• Gm1/Gm2: 현재 세트에서 Player1/Player2가 획득한 게임 수\n• Pts: 현재 게임의 포인트 스코어 (예: 15-30)\n## 게임 진행 상황\n• Gm#: 'X (Y)' 형태로, X=전체 경기의 게임 번호, Y=해당 게임의 포인트 번호\n• TbSet: 세트가 타이브레이크로 결정되는지 여부 (1=예, 0=아니오)\n• TB?: 해당 포인트가 타이브레이크의 일부인지 (1=예, 0=아니오)\n• TBpt: 타이브레이크 포인트 번호\n## 서브/리턴 정보\n• Svr: 서브하는 플레이어 (1=Player1, 2=Player2)\n• Ret: 리턴하는 플레이어 (1=Player1, 2=Player2)\n• Serving: 서브하는 플레이어의 이니셜\n## 서브 및 랠리 상세 정보\n• 1st: 첫 번째 서브의 결과를 나타내는 코드 시퀀스\n• 2nd: 두 번째 서브의 결과를 나타내는 코드 시퀀스 (해당될 경우)\n• Notes: 경기 기록자의 자유 형식 메모\n## 서브 스타일\n• 1stSV: 첫 번째 서브가 서브앤발리 시도였는지 (1=예, 0=아니오)\n• 2ndSV: 두 번째 서브가 서브앤발리 시도였는지\n## 서브 성공/실패\n• 1stIn: 첫 번째 서브가 인(성공)했는지 (1=성공, 0=실패)\n• 2ndIn: 두 번째 서브가 인했는지\n## 포인트 결과 분석\n• isAce: 에이스로 포인트가 결정됐는지 (TRUE/FALSE)\n• isUnret: 리턴 선수가 서브를 되돌리지 못했는지\n• isRallyWinner: 포인트가 위너(에이스 제외)로 끝났는지\n• isForced: 강제 에러로 포인트가 끝났는지\n• isUnforced: 비강제 에러로 포인트가 끝났는지\n• isDouble: 더블폴트였는지\n## 최종 결과\n• PtWinner: 포인트 승자 (1=Player1, 2=Player2)\n• isSvrWinner: 서버가 포인트를 이겼는지 (1=승리, 0=패배)\n• rallyCount: 랠리 샷 수 (서브 포함, 에러는 제외하는 일반적 규칙)\n# 테니스 데이터 전처리 정리\n## 데이터 개요\n### 데이터 구성\n• 남자 테니스: charting-m-points-* 파일들\n• 여자 테니스: charting-w-points-* 파일들\n• 파일 별 연도: 2020s, 2010s, to-2009\n### 주요 컬럼\n• 경기 정보: match_id, date, gender, tournament, round\n• 선수 정보: player1, player2, player1_pts, player2_pts\n• 포인트 정보: Pt, Set1, Set2, Gm1, Gm2, Pts, PtWinner\n• 서브 정보: Svr, 1st, 2nd\n• 기타: Gm#, TbSet, Notes\n---\n## 결측치 분석\n### 전체 결측치 현황\n### 남자 테니스 (m_data)\n```plain text\nGm1       1개 (0.000089%)\nGm2       2개 (0.000178%)\nGm#       1개 (0.000089%)\nTbSet     1개 (0.000089%)\n2nd      702,766개 (62.37%)\nNotes   1,023,383개 (90.83%)\n\n```\n### 여자 테니스 (w_data)\n```plain text\nGm#       1개 (0.000204%)\n2nd      308,083개 (62.94%)\nNotes    472,679개 (96.70%)\n\n```\n### 결측치 유형 분석\n### 의미있는 결측치 (자연스러운 결측)\n• 2nd: 첫 번째 서브 성공시 두 번째 서브 없음\n• Notes: 특별한 상황이 없으면 메모 없음\n### 데이터 오류로 인한 결측치\n• Gm1, Gm2: 게임 스코어 누락 (극소량)\n• Gm#: 게임 번호 누락 (극소량)\n• TbSet: 타이브레이크 여부 누락 (극소량)\n---\n## 결측치 처리 방법\n### 1. 의미있는 결측치 → 유지\n```python\n# 2nd, Notes는 결측치 그대로 유지\n# 억지로 채우지 않음\n\n```\n### 2. 데이터 오류 결측치 → 전후 맥락으로 추론\n### Gm1, Gm2 결측치 해결\n```python\n# 예측 결과:\ndf.loc[222294, 'Gm1'] = 5.0  # 게임 진행 중\ndf.loc[52922, 'Gm2'] = 0.0   # 게임 리셋 상황\ndf.loc[193354, 'Gm2'] = 4.0  # 게임 진행 중\n\n```\n### Gm# 결측치 해결\n```python\n# 분석 결과: 같은 게임 진행 중\ndf.loc[30490, 'Gm#'] = 12.0\n\n```\n### TbSet 결측치 해결\n```python\n# 같은 경기의 다른 포인트들과 동일한 값으로 처리\n# (구체적 분석 필요)\n\n```\n---\n## Notes 컬럼 분석\n### 남자 테니스 Notes\n• 결측치: 90.83%\n• 주요 내용:\n  • Unknown (5,242개)\n  • Let 관련 (6,682개)\n  • 숫자 코드 (57,488개) - 의미불명\n• 결론: 삭제 (품질 낮음)\n### 여자 테니스 Notes\n• 결측치: 96.70%\n• 주요 내용:\n  • Let 관련 (5,141개, 31.8%)\n  • Challenge 관련 (명시적)\n  • 코치/토스 관련 정보\n• 결론: 삭제 (결측치 너무 많음)\n---\n## 데이터 병합 시 주의사항\n### 인덱스 중복 문제\n```python\n# 문제: concat 시 인덱스 중복 발생\nm_data = pd.concat([data6, data7, data8], axis=0)  # 잘못된 방법\n\n# 해결: ignore_index=True 사용\nm_data = pd.concat([data6, data7, data8], axis=0, ignore_index=True)\n\n```\n---\n## 최종 전처리 결과\n### 처리 완료된 항목\n✅ 데이터 병합 (인덱스 리셋)\n✅ 극소량 결측치 수정 (Gm1, Gm2, Gm#)\n✅ Notes 컬럼 제거\n✅ 의미있는 결측치 유지 (2nd)\n### 최종 데이터 상태\n```python\n# 남자 테니스\nprint(\"남자 테니스 결측치:\")\nprint(m_data.isnull().sum()[m_data.isnull().sum() > 0])\n# 결과: 2nd 컬럼만 의미있는 결측치 보유\n\n# 여자 테니스\nprint(\"여자 테니스 결측치:\")\nprint(w_data.isnull().sum()[w_data.isnull().sum() > 0])\n# 결과: 2nd 컬럼만 의미있는 결측치 보유\n\n```\n---\n## 다음 단계\n## EDA 진행\n### 모멘텀 분석 준비\n• 포인트별 승률 계산\n• 최근 N포인트 기반 모멘텀 지표 생성\n• 게임/세트 레벨 모멘텀 계산\n### 추가 전처리 고려사항\n• 서브 코드(1st, 2nd) 파싱\n• 중요한 포인트 식별 (듀스, 브레이크포인트)\n• 경기별 통계 파생변수 생성"
  },
  {
    "page_id": "23da296c-8853-8053-b81b-e9174b30ba1a",
    "title": "물리 AI 자료조사 2차",
    "created_time": "2025-07-27T08:49:00.000Z",
    "last_edited_time": "2025-07-27T08:50:00.000Z",
    "properties": {
      "유형": "자료조사",
      "생성 일시": "2025-07-27T08:49:00.000Z",
      "날짜": {
        "start": "2025-07-17",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:50:00.000Z",
      "이름": "물리 AI 자료조사 2차"
    },
    "content": "# 1. 3D 스캐닝 기반 지도\n• Magiscan으로 공간 스캔\n  [Image: notion_images/23da296c-8853-8053-b81b-e9174b30ba1a_23da296c-8853-8000-8db6-d8f8a59d6ea3.png] - Magiscan으로 하마랩 회의실을 스캔한 결과\n  [Image: notion_images/23da296c-8853-8053-b81b-e9174b30ba1a_23da296c-8853-80c2-a3bc-de4039b75bf4.png] - 우산 스캔 결과\n# 2. 3D 기반 행동 예측 개발\n옴니버스(Omniverse)\n•  엔비디아(NVIDIA)가 개발한 차세대 3D 협업 및 시뮬레이션 플랫폼\n• 실제 세계의 정보를 3D 가상 공간(디지털 트윈)으로 재현\n• 이 위에서 여러 사람이 실시간 협업, 시뮬레이션, AI 데이터 생성, 산업용 애플리케이션 개발까지 한 번에 처리할 수 있도록 생성\n[Image: notion_images/23da296c-8853-8053-b81b-e9174b30ba1a_23da296c-8853-806e-82a2-e15c620d9501.png]\n## CASE 1. CCTV 영상이 부족한 경우\n## 1) 디지털 트윈 구축\n[Image: notion_images/23da296c-8853-8053-b81b-e9174b30ba1a_23da296c-8853-802e-95a0-ec5db03c73ee.png]\n• 실제 공간(실내/실외)을 3D로 스캔(Magiscan)하고, Omniverse에서 정밀한 디지털 트윈(가상복제환경) 생성\n[Image: notion_images/23da296c-8853-8053-b81b-e9174b30ba1a_23da296c-8853-8089-953f-d041746461e5.png] - 옴니버스에 불러온 결과\n## 2) Omniverse에서 시뮬레이션\n• 구축된 디지털 트윈 공간 내에서 다양한 행동/상황(사람 이동, 군중 흐름, 장비 운용 등)을 직접 시뮬레이션 및 실험\n• 실측 데이터 없이도, “만약 ~라면?” 상황을 마음껏 설계하고 테스트\n## 3) Cosmos로 고품질 합성 영상 데이터셋 생성\n• Omniverse의 시뮬레이션 결과(3D 장면, 행동 경로, 각종 변동 상황 등)를 Cosmos에 전송\n• Cosmos는 이를 기반으로 사실적 영상을 대량 합성(각도, 조명, 시나리오, 변형 등), AI 학습용 ‘영상 데이터셋’을 다양한 형태로 생성\n## 4) Omniverse에서 반복 테스트 및 시나리오 확장\n• Cosmos가 만든 영상 및 데이터셋을 바탕으로, 다시 Omniverse에서 새로운 시뮬레이션과 테스트를 진행\n• 이 과정에서 발견되는 추가 행동, 위험 요소, 새로운 상황 등을 반영해 시나리오를 확장 또는 세분화\n## 5) 반복적 데이터셋 생성 및 모델 학습 강화\n• Omniverse의 추가 실험 결과 역시 Cosmos로 보내 더 많은 고품질 합성 영상 데이터를 생성\n• 이렇게 축적된 대규모, 고다양성, 고품질 데이터셋을 이용해 AI/머신러닝 모델을 반복적으로 학습/개선\n## 요약\n• 디지털 트윈 → Omniverse 시뮬레이션 → Cosmos 영상 데이터셋화 → 반복 테스트 및 추가 데이터 생성 → AI 모델 학습\n• 사람·장비 행동 예측, 동선 분석 등 다양한 실내 환경 응용 분야에서 손쉽게 활용 가능\n[Bookmark: https://www.youtube.com/watch?v=Q5xgW9uajC4]\n## CASE 2. CCTV 영상이 있는 경우\n## 1) 3D CNN 기반 영상 학습\n## 2) 성능이 좋은 경우\n• Omniverse  등 3D 플랫폼을 활용하여\n  • 실제 공간/현장 상황을 디지털 트윈으로 모델링\n  • AI 예측 결과(행동 경로, 이벤트)를 3D 아바타, 스켈레톤, 메시 등으로 실시간 연출\n## 3) 성능이 좋지 않은 경우\n• Omniverse 등 3D 플랫폼을 활용하여\n  • 실제 공간/현장 상황을 디지털 트윈으로 모델링\n• 시뮬레이션을 기반으로 Cosmos를 활용해 데이터 생성 후 재학습\n# 3. Cosmos 상용화 사례(로봇 기반)\n## 3-1. Agility Robotics-Digit\n• Agility Robotics는 엔비디아의 파트너사로서, Digit에 Cosmos 플랫폼을 조기 적용하는 대표 사례\n• 2025년 상반기부터 Cosmos Transfer WFM(합성 데이터 생성), Omniverse Mega Blueprint(디지털 트윈 대규모 시뮬레이션) 등 신기술을 도입해 Digit의 훈련과 테스트에 활용\n• 물류창고, 제조현장 등에서 반복 운반·적재·분류 작업을 효과적으로 수행\n• ProMat 2025 쇼에서 28시간 연속 가동, 98.96% 작업 성공률\n• 가격 :  한화로 약 3억 3,000만~3억 4,000만 원 수준\n\n  | 항목 | Digit 주요 사양 |\n  | 신장 및 중량 | 1.75m(5’9″), 약 65kg(143파운드) |\n  | 이동 속도 | 최대 5km/h (3.1mph) |\n  | 적재(포장) 무게 한계 | 최대 16kg(35파운드) |\n  | 배터리 지속 시간 | 최대 4~8시간 (작업 난이도별 상이) |\n  | 독자적 복구 | 넘어져도 스스로 일어날 수 있음 |\n  | 센서 구성 | 라이다, 4개 인텔 RealSense 카메라, MEMS IMU 등 |\n  | 팔/손 기능 | 3자유도 손·팔, 다양한 물체 파지 및 조작 가능 |\n  | 특수 기어·구동 | 험지, 계단 오르내림, 장애물 자율 회피, 좁은 공간 이동 |\n## 3-2. Figure 02\n• VIDIA의 Cosmos 플랫폼의 초기 핵심 파트너 로봇 \n• Figure AI에는 Cosmos 기반 데이터와 NVIDIA의 Omniverse 시뮬레이션이 통합된 개발 파이프라인이 구축됨\n• 가격 : 3억으로 예측(아직 미출시)\n\n  | 항목 | 내용 |\n  | 이름 | Figure 02 |\n  | 크기/무게 | 약 168cm / 70kg |\n  | 작동 시간 | 5시간 연속(통합 배터리), 완전 전기식 |\n  | 적재 능력 | 20kg 이상 |\n  | 손/팔 | 16 자유도 손, 다중 관절, 고정밀 작업 가능 |\n  | 센서 | 6개 RGB 카메라, LiDAR, 촉각·압력·자이로 등 |\n  | AI 모델 | 자체 개발 ‘헬릭스(Helix)’ VLA(비전-언어-동작) 탑재 |\n  | 특징 | 두 대 이상 동시 제어, 자율 환경 적응, 대화형 작업 지원 |\n  | 적용 분야 | 제조·물류 자동화, 지속적 확장 예정(가정용 알파 테스트 포함) |"
  },
  {
    "page_id": "23da296c-8853-8062-bc9d-efab868673ed",
    "title": "아쿠아누리 예측값 json 구조",
    "created_time": "2025-07-27T08:45:00.000Z",
    "last_edited_time": "2025-07-27T08:45:00.000Z",
    "properties": {
      "유형": "계획",
      "생성 일시": "2025-07-27T08:45:00.000Z",
      "날짜": {
        "start": "2025-07-25",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:45:00.000Z",
      "이름": "아쿠아누리 예측값 json 구조"
    },
    "content": "```sql\n{\n  \"data\": \n    {\n      \"ff_unique_id\": \"farm_001\",       // 양식장 ID\n      \"ft_unique_id\": \"tc1\",            // 수조 ID\n      \"se_unique_id\": \"se1\",            // 센서 ID\n      \"prediction\": {\n        \"2025-07-25 10:00:00\": {\n          \"ssd_ph_value\": 23.5,\n          \"ssd_do_value\": 23.5,\n          \"ssd_temp_value\": 23.5,\n          \"ssd_salinity_value\": 23.5\n        },\n        {\n        \"2025-07-25 11:00:00\": {\n          \"ssd_ph_value\": 24.5,\n          \"ssd_do_value\": 23.8,\n          \"ssd_temp_value\": 25.5,\n          \"ssd_salinity_value\": 22.5\n        }\n      }\n    }\n  \n}\n```"
  },
  {
    "page_id": "23da296c-8853-8075-afd1-ca7daa3c3e7f",
    "title": "테니스 기본 규칙 및 모멘텀 예측 논문 리뷰",
    "created_time": "2025-07-27T08:47:00.000Z",
    "last_edited_time": "2025-07-27T08:48:00.000Z",
    "properties": {
      "유형": "자료조사",
      "생성 일시": "2025-07-27T08:47:00.000Z",
      "날짜": {
        "start": "2025-07-22",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:48:00.000Z",
      "이름": "테니스 기본 규칙 및 모멘텀 예측 논문 리뷰"
    },
    "content": "# 테니스 점수\n• 점수 체계 : 0 → 15 → 30 → 40\n• 듀스인 경우 = 40 : 40 → 연달아 2포인트가 있어야됨\n# 논문 리뷰 - Capturing Momentum: Tennis Match Analysis Using Machine Learning and Time Series Theory\n[Image: notion_images/23da296c-8853-8075-afd1-ca7daa3c3e7f_23da296c-8853-8080-a45a-f8e974c97193.png]\n## 주제에서 어떤 이슈들이 있는가\n• 모멘텀의 정의와 정량화: 경기 중 '모멘텀'을 객관적이고 수치적으로 표현하는 것이 쉽지 않음.\n• 모멘텀의 존재 증명: 경기 흐름에 모멘텀이 실질적 영향을 미치는지 실증적 분석 부족.\n• 변화 탐지: 모멘텀 전환 지점을 어떻게 탐지할지에 대한 명확한 방법이 부족\n## 이를 해결하기 위한 기존 해결책과 한계점\n• Markov Chain: 기존 연구들은 대부분 Markov 모델을 이용해 서브 확률에 따라 승리 예측 (Barnett et al., Newton 등).\n• 한계점:\n  • 서브 확률을 고정값으로 두거나 단순히 점진적 업데이트만 반영\n  • 경기 중 실질적인 모멘텀 전환이나 선수 심리 상태 반영에 한계\n  • 기존 모델들은 경기 흐름의 연속적 변동, 즉 '모멘텀'을 수치화하는데 적합하지 않음\n## 한계점을 극복하기 위해 이 논문이 제시한 솔루션\n• Hidden Markov Model (HMM)을 사용해 숨겨진 상태(모멘텀)의 전이 확률을 추정하고 EMA (지수이동평균)을 통해 모멘텀 수치화\n• XGBoost를 통해 모멘텀의 유의성을 검증하고, LightGBM + SHAP을 활용해 모멘텀 전환에 영향을 주는 주요 특성 도출\n• 다양한 데이터셋에 적용해 일반화 가능성 검토 및 정확도, 민감도 평가\n• 경기 전략 및 사전 준비에 대한 구체적 제언까지 제시\n\n  | 단계 | 내용 | 사용 기법 / 목적 |\n  | A | 데이터 전처리 (Data Cleaning) | 데이터 정제, 포인트 누적, 변수 생성 등 사전 준비 |\n  | B | 모멘텀 찾기 (Momentum Estimation) | Hidden Markov Model (HMM) + EMA로 모멘텀 수치화 |\n  | C | 모멘텀 유의성 검증 (Significance Test) | XGBoost 사용, 모멘텀이 승패 예측에 유의한지 검증 |\n  | D | 주요 요인 탐색 (Feature Importance) | LightGBM + SHAP 으로 영향력 큰 변수 도출 |\n  | E | 모델 평가 (Model Evaluation) | 정확도, 일반화 가능성 검토 (US Open 등 다른 대회 테스트) |\n# 모멘텀 예측 지수는 어떻게 계산했는가?\n→ HMM (Hidden Markov Model) + EMA (Exponential Moving Average)\n• HMM: 경기 중 숨겨진 상태(모멘텀 상태)를 추정\n• EMA: HMM으로 얻은 상태 전이 확률을 부드럽게 smoothing → 모멘텀 수치화\n## HMM (Hidden Markov Model)\n• HMM = 시간에 따른 숨겨진 상태 전이 + 관측값 발생\n• 상태는 시간 순서에 따라 이전 상태 → 현재 상태로 전이 (Markov assumption)\n• 관측값은 현재 상태로부터 영향을 받음 (Emission probability)\n[Image: notion_images/23da296c-8853-8075-afd1-ca7daa3c3e7f_23da296c-8853-80b2-9e07-c5d1a36f24ce.png]\n\n  | HMM 요소 | 테니스에서의 의미 |\n  | 숨겨진 상태 i_t | 모멘텀 상태 (경기 흐름 상 유리한 쪽) |\n  | 관측값 o_t | 실제 포인트 승패, 서브 성공 등 |\n  | 상태 전이 A | 경기 흐름이 바뀌는 확률 |\n  | 관측 확률 B | 특정 상태일 때 특정 결과가 나타날 확률 |\n[Image: notion_images/23da296c-8853-8075-afd1-ca7daa3c3e7f_23da296c-8853-8089-8f51-f7ab123680cd.png]\n• 경기 관련 변수들과 승리 확률(Probability of Winning) 간의 상관관계 분석 결과.\n• 특히, 모멘텀 값과 승리 확률 간의 상관계수가 높음을 보여줌.\n• 모멘텀이 실제로 승리 확률과 밀접하게 연관이 있다는 통계적 근거 제시.\n• 예를 들어, 서버가 누구냐(serve percent), 모멘텀 수치 등이 경기 흐름(승리 가능성)에 영향을 준다는 점을 수치적으로 보여줌.\n• 이로 인해 모멘텀을 모델링하는 것이 합리적이라는 근거를 제공.\n## 모델 성능을 ROC Curve와 AUC로 평가\n\n  | 용어 | 의미 |\n  | TPR | 얼마나 Positive를 잘 찾았는가 (Recall) |\n  | FPR | 얼마나 잘못 Positive라 예측했는가 |\n  | AUC | ROC 아래 넓이, 모델 성능 척도 (1에 가까울수록 좋음) |\n## 모멘텀 없이 모델 학습 vs 있는 상태에서 학습\n\n  | 모델 | Feature Importance 결론 |\n  | 랜덤 모멘텀 (a) | 모멘텀이 없는 모델 → 흐름 예측 어려움 |\n  | 제안 모멘텀 (b) | 모멘텀이 핵심 변수로 작동함 |"
  },
  {
    "page_id": "23da296c-8853-80b8-98b7-da81d646afe3",
    "title": "물리 AI 자료조사",
    "created_time": "2025-07-27T08:50:00.000Z",
    "last_edited_time": "2025-07-27T08:50:00.000Z",
    "properties": {
      "유형": "자료조사",
      "생성 일시": "2025-07-27T08:50:00.000Z",
      "날짜": {
        "start": "2025-07-17",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:50:00.000Z",
      "이름": "물리 AI 자료조사"
    },
    "content": "# 물리 AI란?\n• 디지털 세계를 넘어 실제 물리적 환경에서 작동하며, 로봇, 자율주행차 등을 통해 현실 세계와 직접 상호작용하는 특징을 가짐\n• 최근 발달하는 LLM 및 멀티모달 기술과 결합하여 더욱 빠르게 진화할 것으로 예상되는 분\n• 센서 융합, 실시간 제어, 환경 적응 학습이 핵심 기술이며, 휴머노이드 로봇, 자율주행차, 스마트 팩토리 등의 형태로 구현\n## 물리 AI의 특징\n• 다양한 센서를 통해 주변 환경 변화를 감지하고 즉각 대응하는 실시간 환경 인식 및 적응 능력\n• 로봇팔, 그리퍼 등을 통해 객체를 조작하고 이동하는 물리적 조작 능력\n• 경험을 통해 지속적으로 성능을 개선하며 새로운 상황에 적응하는 학습과 진화 능력\n## 물리 AI의 구성 요소\n• 센서 기술\n  • AI가 주위 환경을 정확하게 인식하기 위한 핵심으로, LiDAR, 카메라, 레이더, IMU(관성측정장치) 등이 사용\n  • 이들 센서는 융합되어 360도 환경 인식, 정밀 거리 측정, 객체 인식을 가능하게 함\n• AI 모델\n  • 환경과의 상호 작용으로 최적 행동 패턴을 학습하는 강화학습이 핵심적\n  • 전문가 행동을 모방하는 모방학습(Imitation Learning)도 빠른 학습을 위해 활용\n• 시뮬레이션 환경\n  • Unity, NVIDIA Isaac Sim 등의 플랫폼을 사용하여 실세계와 유사한 환경에서 안전한 학습과 검증을 수행\n  • 이는 위험하거나 비용이 많이 드는 실제 테스트를 보완\n• 액추에이터 기술\n  • 물리적 동작을 실행하는 부분으로, 모터 등이 포함되며 정밀한 제어와 빠른 응답 속도가 요구\n  • 최근에는 소프트 액추에이터 등 새로운 방식도 개발\n# 로봇 물리 AI\n• 물리 AI를 통해 로봇은 다양한 환경에서 운용 성능이 눈에 띄게 향상\n• 예시\n  • 창고의 자율 이동 로봇(AMR)\n    • 온보드 센서의 직접적인 피드백을 사용하여 복잡한 환경을 탐색하고 인간을 포함한 장애물을 피할 수 있음\n  • 조작기\n    • 컨베이어 벨트 위의 물체 자세에 따라 파지 강도와 위치를 조정\n    • 대상 유형에 맞는 정밀한 소운동과 대운동 기술을 모두 보여줌\n  • 수술 로봇\n    • 이 기술을 통해 바늘 꿰기, 봉합 등과 같은 정교한 작업을 학습\n  • 휴머노이드 로봇\n    • 즉 범용 로봇은 주어진 작업이 무엇이든 간에, 물리적 세계를 인식하고, 이해하며, 탐색하고, 상호작용할 수 있는 능력과 함께 대운동과 소운동 기술 모두를 갖추어야 합니다.\n# 코스모스 AI\n\n\n    [Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-80ca-811a-ee50dc3bd446.png]\n\n    [Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-80e3-8f5d-c3133da1dff1.png]\n• 물리적 AI 시스템 개발을 가속화하기 위한 최첨단 생성형 세계 기초 모델(World Foundation Models, WFMs) 플랫폼\n## 주요 기능\n[Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-80b2-8829-c5996c5ff42d.png]\n1. 비디어 검색 및 이해\n• 비디오 검색\n  • 비디오 데이터에서 특정 훈련 시나리오를 쉽게 찾을 수 있도록 도와줌\n  • 예시 :  눈이 내리는 도로 상황이나 창고의 혼잡 같은 특수 상황을 빠르고 정확하게 검색\n• 비디오 생성\n  • 완전히 새로운 합성(Synthetic) 영상을 만들고 싶을 때, “프롬프트(문장)” 형태로 원하는 상황을 입력하면 AI가 해당 내용을 바탕으로 비디오를 직접 생성\n\n\n    [Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-80c9-b93c-d6232df6ca3d.png]\n\n    [Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-806d-8ca9-e219ebd46c23.png]\n1. 통제 가능한 3D-실제 합성 데이터 생성\n• 프롬프트로 만든 데이터나 검색된 실제 비디오를 Omniverse에서 3D 시나리오로 구현한 뒤, 그 위에 Cosmos의 AI 합성 기능을 더해 실제와 흡사한 영상을 생성\n• 이를 통해 훈련 데이터의 신뢰성을 높이고, 합성 데이터를 효율적으로 활용\n1. 정책 모델 훈련 및 평가\n• 기초 모델을 기반으로 맞춤형 모델을 구축하거나, 강화 학습을 통해 모델을 개선하거나, 특정 시뮬레이션 시나리오에서 모델이 어떻게 작동하는지 테스트\n• 이로써 실제 환경에서의 위험한 테스트를 최소화할 수 있음\n## 결론\n• 코스모스와 Omniverse를 사용하여 물리적 AI 모델이 가능한 모든 미래 결과를 시뮬레이션 후 가장 정확하고 최적의 경로를 선택할 수 있도록 지원\n## 기술 구성 요소\n[Image: notion_images/23da296c-8853-80b8-98b7-da81d646afe3_23da296c-8853-8036-996d-f2513c006bdb.png]\n오토리그레시브 모델\n• 엔비디아 코스모스 오토리그레시브 모델은 비디오 또는 이미지 입력에서 고품질의 물리적 비디오를 예측하고 신속하게 생성하는 사전 훈련된 모델 모음\n디퓨전 모델\n• 텍스트, 이미지 또는 비디오 입력에서 고품질의 동적 비디오를 생성할 수 있는 모델 모음\n데이터 처리 파이프라인\n• NVIDIA NeMo Curator를 기반으로 하는 가속화된 데이터 처리 파이프라인\n• 2천만 시간의 비디오 데이터를 14일 만에 처리\n비주얼 토크나이저\n• 이미지와 비디오를 효율적으로 토큰화하여 비디오 압축율을 높이고, 처리 속도를 크게 향상\n• 훈련 및 추론 과정에서 뛰어난 품질과 비용 절감을 제공\n## 주요 사용 사례\n자율주행 차량\n• 자율주행차의 훈련 데이터를 생성하고, 안전성을 검증하는 시나리오를 테스트하는 데 활용\n• 우버, 와비, 웨이브와 같은 자율주행 기술 선도 기업들이 코스모스를 채택\n• 실제 주행 데이터와 Cosmos 생성 데이터를 결합해 자율주행차용 AI 훈련–평가를 신속·유연하게 반복 적용\n로봇 공학\n• 로봇 공학에서는 다양한 물리적 환경에서 로봇이 학습할 수 있도록 시나리오를 생성\n• 기업들은 코스모스를 사용하여 로봇의 훈련 데이터를 증강하고, 실제 데이터 수집 없이도 모델을 효과적이고 경제적으로 훈련\n⇒ 로봇, 자율주행, 물류, 제조현장 등에서 실제 데이터 수집이 어렵거나, 대규모 반복 실험이 필요한 환경에서 가장 활발히 도입·확산\n# 기존 유사 모델\n### Parallel domain - PD Replica Sim \n• 자율 시스템 테스트에 필요한 고충실도, 결정론적 시뮬레이션 제공\n• 강점\n  • 정밀한 제어: 센서·환경 파라미터 완벽 통제 가능 (카메라, LiDAR, RADAR 등 멀티센서)\n  • 정확한 주석: 깊이, 바운딩 박스, 모션 벡터, 세분화 등 동기화된 GT 데이터 제공\n  • 고해상도 지원: 8MP까지 지원, 실제 센서 스펙 반영\n  • 반복 가능성: 동일 조건 반복 테스트에 최적화 (규정 준수, 회귀 테스트)\n  • 빠른 테스트 속도: 대규모 AI 오버헤드 없이 빠른 실행\n• 한계\n  • 멀티모달 통합 부재: 센서·카메라 중심, 다양한 데이터 융합은 어려움\n  • 범용성 부족: 자율주행/로보틱스 외 확장성 한계\n### Wayve GAIA\n• 실제 도로 주행 데이터를 기반으로, 미래 주행 장면을 비디오로 직접 생성할 수 있는 첨단 생성 AI 모델\n• 강점\n  • 현실적 합성 시나리오 생성\n실제로 경험하기 어려운 다양한/희귀한 도로 상황도 비디오로 예측·합성할 수 있어, AI의 잠재적 위험 대처 능력을 크게 높임.\n  • 데이터 효율성\n실제 도로에서 방대한 데이터 수집 없이, 시뮬레이션으로 폭넓은 상황에 빠르게 노출·학습이 가능\n  • 범용성\n다양한 차종과 환경(도시, 교외, 기상 등)에 대응할 수 있도록 설계되어 자동차 제조사나 자율주행 사업에 응용 가능성이 높임.\n  • 엔드 투 엔드 통합\n인식~판단~행동계획~제어 전 단계를 하나의 AI 스택에서 처리, 전체 시스템의 최적화와 일관성을 확보\n• 한계\n  • 승용차 자율주행 중심이여서 다른 분야까지 확장되기 어려움\n  • 특정 하드웨어 및 제조사 협의가 필요\n  • 자사, 파트너 대상 내부 사용/검증이 중심이여서 데이터의 한계가 존재\n### PhysicsAI Studio\n• 클라우드에서 동작하는 물리 예측 통합 환경으로, 실험 및 시뮬레이션 데이터를 바탕으로 AI 모델을 학습해 신규 형상 및 조건에서도 물리 현상을 예측\n• CAD·메시 등 복잡한 형상을 기하학적으로 이해하는 딥러닝 방식이 적용\n• 장점\n  • 모델 기반 신규 물리 데이터 즉각 생성\n    학습 데이터로부터 추론해 새 형상·조건의 물리 결과를 빠르게 예측, 실시간에 가까운 의사결정 및 설계 검증이 가능\n  • 클라우드 기반 접근성과 확장성\n별도 하드웨어나 전용 시스템 없이 웹 플랫폼에서 조직 내외 다양한 인력이 실시간 협업\n  • 모델 신뢰성 확보\n예측 신뢰 점수(geometric confidence score)로 AI의 예측 결과 품질을 사전에 진단할 수 있어, 실 업무 적용에도 안정성이 돋보임\n• 한계\n  • 과거 데이터 분포 내 예측(현실성·재현 범위 한정)\n  • 구조/유동/열 해석 등 전통 공학(CAE) 중심에 초점이 맞춰져 있어 자율주행, 로보틱스 등 다목적 AI·산업 시뮬레이션 분야의 범용적으로 한계\n  •  ‘세상에서 일어나지 않는’ 데이터/상황 임의 생성까지는 어려움\n# 활용방안\n• 다양한 분야에 적용 가능\n• 합성 데이터 생성 및 실사 3D 시뮬레이션\n  • Cosmos와 NVIDIA Omniverse를 연동하면 개발자가 제어 가능한 3D 시나리오를 만들고, 현실과 유사한 상황을 재현한 비디오 데이터셋을 생성\n  • 실제 도로, 복잡한 창고, 다양한 날씨/조명 환경 등 현장에서 수집하기 힘든 데이터를 합성해 AI 훈련에 활용\n• 로봇과 자율주행 AI 개발 고도화\n  •  로봇의 행동 정책을 훈련·평가하는 데 직접 활용\n  • 예측 기반 시뮬레이션을 통해 장애물 회피, 경로 탐색, 다양한 조작 시나리오를 위험 부담 없이 실험\n  • 실세계 테스트와 비교해 개발 속도와 안전성이 크게 향상\n# 참고자료\n[Bookmark: https://m.digitalmarket.kr/m/board/BD_board.view.do?domainCd=2&bbsCd=1030&q_currPage=1&bbscttSeq=20250530103416106]\n[Bookmark: https://www.themoonlight.io/ko/review/cosmos-world-foundation-model-platform-for-physical-ai]\n[Bookmark: https://www.nvidia.com/ko-kr/on-demand/session/gtc25-dlit74500/]\n[Bookmark: https://developer.nvidia.com/blog/advancing-physical-ai-with-nvidia-cosmos-world-foundation-model-platform/]\n[Bookmark: https://paralleldomain.com/cosmos-vs-pd-replica-sim]\n[Bookmark: https://www.youtube.com/watch?v=GsB7tGB5g-o]"
  },
  {
    "page_id": "23da296c-8853-80cc-82c7-d86561202e6c",
    "title": "줄넘기 수집데이터 전처리",
    "created_time": "2025-07-27T08:51:00.000Z",
    "last_edited_time": "2025-07-27T08:51:00.000Z",
    "properties": {
      "유형": "프로젝트현황",
      "생성 일시": "2025-07-27T08:51:00.000Z",
      "날짜": {
        "start": "2025-07-13",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:51:00.000Z",
      "이름": "줄넘기 수집데이터 전처리"
    },
    "content": "• basic 10개 전처리 진행\n• 11개째 진행중\n• 차주 월요일 basic 전처리 및 double 전처리 완료하기\n• 화요일-수요일 오전까지 끝내기"
  },
  {
    "page_id": "23da296c-8853-80d0-875f-f789eba0551b",
    "title": "동영상 정보 추출 기술 조사",
    "created_time": "2025-07-27T08:20:00.000Z",
    "last_edited_time": "2025-07-27T08:45:00.000Z",
    "properties": {
      "유형": "자료조사",
      "생성 일시": "2025-07-27T08:20:00.000Z",
      "날짜": {
        "start": "2025-07-25",
        "end": null
      },
      "최종 편집 일시": "2025-07-27T08:45:00.000Z",
      "이름": "동영상 정보 추출 기술 조사"
    },
    "content": "메타데이터는 크게 텍스트 기반 메타데이터와 이미지/영상 기반 메타데이터로 구분되며, 각각의 수집 및 활용 방식은 다음과 같다.\n1. 텍스트 기반 메타데이터 수집\n  콘텐츠의 설명 정보, 제목, 줄거리, 감독, 배우, 자막 등 텍스트 형태의 데이터를 자동으로 수집한다.\n• 주요 기술\n  • SRT (SubRip Subtitle):\n    가장 널리 사용되는 자막 파일 형식으로, 자막 블록마다 시작 및 종료 시간(타임스탬프)과 해당 텍스트가 포함된다. 이 정보를 활용해 자막 내용을 시간 정보와 함께 저장할 수 있다.\n  • OpenAI Whisper\n    영상 내 음성을 텍스트로 자동 변환하는 STT(Speech-to-Text) 기술로, 자막이 없는 영상에서도 텍스트 정보를 추출할 수 있다. \n  • KoBERT\n    자막/대사 단위 텍스트에서 감정(기쁨, 슬픔, 분노, 불안 등) 분류 및 주요 감정 키워드 추출할 수 있다\n• 수집 방식\n  영상 및 자막 데이터를 기반으로, 콘텐츠 관리 시스템(CMS)과 연동하여 메타데이터를 확보한다. 수집된 텍스트는 자연어 처리(NLP) 기법을 활용하여 정제 및 분석이 이뤄진다.\n• 전처리 과정\n  • 불용어(stopword) 제거: 의미 없는 단어를 제거해 분석 정확도 향상\n  • 형태소 분석: 문장을 형태소 단위로 분해해 어간 추출 및 품사 분석\n  • 키워드 추출: 텍스트에서 주요 주제어나 핵심 문구 도출\n  • 개체명 인식(NER): 인물, 장소, 날짜 등 특정 개체를 식별하여 구조화\n• 저장 및 활용\n  정제된 텍스트는 JSON 또는 표 형식으로 구조화되어 데이터베이스에 저장된다. 예를 들어, 콘텐츠의 장르를 드라마, 코미디 등으로 분류하고, 제목 및 주요 대사를 메타 필드로 저장해 검색 및 필터링에 활용할 수 있다.\n  \n1. 이미지/영상 기반 콘텐츠 요약 및 추천\n  • 영상 콘텐츠에 대해서는 AI 기반의 시각 정보 분석 기법을 적용하여 주요 장면을 자동으로 추출하고, 추천 및 요약에 활용한다\n  • 주요기술\n    • Clip-based Summarization \n      [Image: notion_images/23da296c-8853-80d0-875f-f789eba0551b_23da296c-8853-806d-8ae0-ca190eb2fd36.png]\n      • 전체 영상에서 특정 장면 전환(샷 전환, 장면 전환)을 탐지하고, 중요한 순간만을 추출하여 짧은 클립 단위로 나눈다\n      • Clip-based Summarization  프로세스\n        1. 비디오 분할 및 프레임 샘플링\n          • 긴 비디오를 일정 길이(예: 3초~10초)로 분할하고, 각 구간의 대표 프레임을 추출\n        1. 특징 추출 및 임베딩(Embedding)\n          • 각 프레임 혹은 클립에서 시각적·오디오적 특징을 AI 모델(예: CLIP, DINO 등)로 추출하여 고차원 벡터로 변환\n        1. 클러스터링 및 의미 단위 구간화\n          • 프레임 임베딩들 간의 유사도를 바탕으로 k-means 등 클러스터링 알고리즘을 적용, 비슷한 내용끼리 그룹화\n          • 클러스터 단위로 비디오를 의미 있는 세그먼트(구간)로 분리\n        1. 중요 구간(클립) 선정\n          • 각 클러스터나 구간에서 대표 프레임이나 중요도가 높은 구간을 선택\n          • 중요도 평가는 장면 변화, 감정 반응, 시각적/음성적 이벤트, 사용자 행동(예: 소셜 북마크 데이터) 등 다양한 기준을 활용할 수 있다\n        1. 요약 영상 생성\n          • 선택된 클립 또는 구간을 순서대로 연결해 전체 스토리나 주제를 대표하는 짧은 영상 요약본을 생성\n    • Video Captioning (영상 캡셔닝)\n      [Image: notion_images/23da296c-8853-80d0-875f-f789eba0551b_23da296c-8853-8003-a3ac-ec8c7b74bf78.png]\n    • 전체 영상이나 특정 클립에 대해 텍스트 설명을 자동 생성 (예: \"아이가 의자에서 춤을 춘다\")\n    • Clip-based Summarization으로 추출된 영상을 기반으로 영상 캡셔닝을 통해 자연어 문장으로 설명한 후 메타데이터로 저장한다\n  • 저장 및 활용\n    이러한 분석을 통해 각 클립은 하나의 특징 벡터(feature vector)로 표현된다. 예를 들어, 클립 내 인물 수, 배경 변화, 감정 표현, 주요 오브젝트 등을 수치화한 벡터가 생성된다. 이 벡터는 콘텐츠 간 유사도를 계산하는 데 사용되며, 특정 사용자가 시청한 장면과 유사한 클립을 자동으로 추천하는 데 활용할 수 있다. 또한, 클립 벡터는 추천 시스템에서 콘텐츠 요약, 개인화 추천, 하이라이트 재생, 검색어 기반 탐색 등의 다양한 기능에 기여한다.\n1. STT 기반 콘텐츠 추천\n  STT(Speech-to-Text) 기술을 활용하면 사용자의 음성을 텍스트로 변환한 후, 이를 기반으로 LLM(대형 언어 모델)과 텍스트 임베딩 기술을 적용하여 맞춤형 콘텐츠를 추천할 수 있다.\n  • 사용자의 음성 입력\n    • 실시간 또는 녹음된 형태로 수집되며, Whisper 등 STT 기술을 이용해 텍스트로 변환된다\n    • 이 텍스트는 자연어 처리 기반 전처리 과정을 거쳐 분석 가능한 형태로 정제된다\n  • 임베딩 기술 연동\n    • GPT, Claude 등 최신 LLM과 BERT, Sentence-BERT, OpenAI Embedding 등의 임베딩 기술을 연동해 사용자의 쿼리나 대화 내용을 벡터로 변환한다. \n    • 생성된 벡터는 콘텐츠 메타데이터 및 클립 특징 벡터가 저장된 벡터 데이터베이스와 비교되어, 가장 유사한 콘텐츠를 빠르게 검색할 수 있다. \n    • 이 과정에는 코사인 유사도, MMR(Maximal Marginal Relevance) 등의 벡터 비교 기법이 사용된다.\n  • 개인화 추천 프로세스\n    1. 다층적 메타데이터 통합\n      텍스트 기반 메타데이터(예: 제목, 줄거리, 장르), 시각 정보 기반의 클립 특징 벡터(예: 인물 수, 감정 스코어, 행동 정보), 그리고 사용자 프로필 정보(선호 장르, 시청 이력, 사용 언어, 감정 경향 등)를 통합하여, 정교한 사용자 맞춤형 데이터 구조를 구성한다.\n    1. LLM을 활용한 자연스러운 추천 설명\n      LLM의 질의응답 기능, 키워드 기반 요약, 상황 맥락 기반 설명 기능을 활용하여 추천 콘텐츠를 사용자의 언어와 맥락에 맞게 자연스럽게 설명하고, 추천의 설득력을 높인다.\n    1. 문화적 감수성과 감정 분석 기반 추천\n      사용자의 발화에 포함된 단어 선택, 문맥, 감정 표현, 문화적 배경 등을 분석하여, 감정적 공감과 문화적 정서를 반영한 콘텐츠를 추천한다. 텍스트 분석뿐 아니라 사용자의 시청 이력에서 감정 선호도를 반영해, 특정 감정(예: 감동, 설렘, 유쾌함 등)을 자극하는 장면이 많은 콘텐츠를 우선 제안할 수 있다.\n    1. 사례 기반 정서 대응 추천\n      예를 들어, 한국 사용자가 \"가볍게 볼 수 있는 웃긴 거\"라고 말하면, 자막과 클립 감정 스코어에서 ‘기쁨’과 ‘유쾌함’이 높은 장면이 포함된 한국 예능을 추천한다. 반면 같은 의미를 스페인어로 발화한 사용자는 스페인 문화권에서 인기 있는 코미디 영화나 시트콤을 추천받게 된다. 이는 언어뿐 아니라 문화적 맥락, 정서 코드, 감정 표현 방식의 차이를 고려한 추천 방식이다.\n  1. 기대효과\n  • 이 시스템은 다국어 STT 및 다국어 LLM을 함께 지원하여, 다양한 언어와 문화권의 사용자에게도 일관되고 품질 높은 개인화 큐레이션을 제공할 수 있다. \n  • 이를 통해 사용자는 단순히 키워드를 입력하는 것이 아니라, 자연스러운 대화를 통해 원하는 콘텐츠를 손쉽게 탐색하고 소비할 수 있다."
  },
  {
    "page_id": "23da296c-8853-80e2-a038-e421835a28f2",
    "title": "테니스 모멘텀 예측 모델 정리",
    "created_time": "2025-07-27T08:46:00.000Z",
    "last_edited_time": "2025-12-14T08:40:00.000Z",
    "properties": {
      "유형": "결과분석",
      "생성 일시": "2025-07-27T08:46:00.000Z",
      "날짜": {
        "start": "2025-07-23",
        "end": null
      },
      "최종 편집 일시": "2025-12-14T08:40:00.000Z",
      "이름": "테니스 모멘텀 예측 모델 정리"
    },
    "content": "# 테니스 모멘텀 예측 모델 개발 프로젝트\n### 목표\n• 테니스 경기 중 모멘텀 변화 예측 모델 개발\n• 실시간으로 다음 포인트의 모멘텀 상태 예측\n• 경기 흐름 분석 및 선수 우세 상황 판단\n### 데이터 규모\n• 총 샘플: 468,644개 포인트\n• 매치 수: 696경기\n• Feature 수: 27개\n• 분할: Train(60%) / Validation(20%) / Test(20%)\n---\n## 1. 데이터 전처리\n### 데이터 구조 변환\n• 1st, 2nd 서브 + 기술 통계 활용\n  • 서브 성공률, 더블폴트, 네트 포인트 등 기록된 데이터 기반\n• 누적시간으로 시계열 변형\n  • elapsed_time을 활용해서 시간 순서대로 정렬\n  • 포인트별 시계열 데이터로 구성\n• 현재 코드 구조\n  • 과거 패턴(lookback_window=5) → 현재 상태 → 다음 예측\n  • 모멘텀 기반 피처 엔지니어링\n### Feature Engineering\n```python\n# 과거 5개 포인트 패턴 분석\n- 최근 승부 패턴 (p1_win_rate_recent, win_streak)\n- 서버 변화 패턴 (server_changes)\n- 성능 통계 (ace_rate, break_opportunities)\n- 점수 차이 (points_diff, sets_diff, ace_diff)\n- 네트 플레이 성공률 (net_success_rate_p1/p2)\n\n```\n---\n## 2. 모멘텀 계산 방법론\n### HMM + EMA 하이브리드 접근법\nHMM (Hidden Markov Model)\n• 숨겨진 모멘텀 상태 추정\n• 시간에 따라 변하는 숨겨진 상태와 관찰 가능한 상태 사이의 관계 모델링\n• 베이지안 네트워크의 동적 버전\n• 시간적 상관관계가 있는 샘플들을 다룰 때 유용\nEMA (Exponential Moving Average)\n• 모멘텀 값 부드럽게 처리\n• 최근 데이터에 더 큰 가중치를 주는 이동평균\n• 오래된 데이터일수록 영향력이 지수적으로 감소\n### 모멘텀 값 해석\n• 0: 균형 상태 (두 선수 우세 확률 동일)\n• +1: Player1이 대체로 우세 (원래 HMM 최대값)\n• +2: Player1이 지속적으로 압도적 우세 (EMA 누적 효과)\n• 1/-2: Player2 우세 (동일한 논리)\n---\n## 3. 모델 개발 과정\n### 초기 모델 (Ver.1) - 높은 성능\n```plain text\n모멘텀 예측 R²: 0.9943\n모멘텀 증가 예측:\n- Accuracy: 97.88%\n- Precision: 96.26%\n- Recall: 95.31%\n- F1-Score: 95.78%\n\n```\n주요 특징:\n• current_momentum Feature 포함 (중요도 1위)\n• 과거 모멘텀 lag 변수들 활용\n• 거의 완벽한 성능이지만 데이터 누수 의심\n### 현재 모델 (Ver.2) - 실제 예측 환경\n### 모델 구조\n```python\n# 1. 모멘텀 값 예측 (회귀)\nLGBMRegressor(\n    objective='regression',\n    num_leaves=31,\n    learning_rate=0.1,\n    feature_fraction=0.9\n)\n\n# 2. 모멘텀 증가 여부 예측 (분류)\nLGBMClassifier(\n    objective='binary',\n    scale_pos_weight=1.5,  # 클래스 불균형 해결\n    num_leaves=31,\n    learning_rate=0.1,\n    feature_fraction=0.9\n)\n\n```\n### 성능 결과\n```plain text\n모멘텀 값 예측 (회귀)\n- Train R²: 0.1891\n- Val R²: 0.1512\n- Test R²: 0.1260\n- MAE: 0.7954\n\n모멘텀 증가 예측 (분류)\n- Test Accuracy: 74.44%\n- Test Precision: 39.60%\n- Test Recall: 2.17%\n- Test F1-Score: 4.12%\n\n```\n---\n## 4. 클래스 불균형 문제 해결\n### 문제 상황\n• 데이터 분포: 감소/유지 75% vs 증가 25%\n• 초기 결과: Precision 34-42%, Recall 64-78%\n• scale_pos_weight=4 적용 후: 극도로 보수적 예측 (Recall 6.4%)\n### 해결 과정\n1단계: 문제 진단\n```plain text\nscale_pos_weight=4 → 너무 강한 가중치\n→ 모든 예측이 \"감소/유지\"로 치우침\n→ Precision/Recall 모두 0.0000\n\n```\n2단계: 가중치 조정\n```python\n# 문제 상황\nscale_pos_weight=4 → Precision: 38.9%, Recall: 6.4%\n\n# 수정 권장안\nscale_pos_weight=1.5 → 예상 Precision: 45-50%, Recall: 50-60%\n\n# 또는 원복\nclass_weight='balanced' → 이전 좋은 결과 유지\n\n```\n### 성능 개선 전략\n임계값 조정 분석\n```plain text\n임계값 0.3: Precision 33.5%, Recall 75.3%, F1 46.4%\n임계값 0.4: Precision 36.8%, Recall 4.0%, F1 7.2%\n임계값 0.5: Precision 39.6%, Recall 2.2%, F1 4.1%\n\n```\n권장 접근법\n1. 즉시 개선: 임계값 0.3 사용으로 F1-Score 46.4% 달성\n1. 근본 개선: scale_pos_weight=1.5로 재학습\n1. 하이브리드: 가중치 + 임계값 조정 조합\n---\n## 5. Feature 중요도 분석\n### 상위 중요 Feature (Ver.2)\n```plain text\n1. net_success_rate_p1     : 80.0\n2. net_success_rate_p2     : 79.0\n3. current_p2_sets         : 55.0\n4. current_p2_net_pt_won   : 54.0\n5. points_diff             : 48.0\n6. current_p1_sets         : 47.0\n7. current_p1_ace          : 46.0\n8. ace_diff                : 45.0\n9. current_p1_net_pt       : 43.0\n10. current_p1_net_pt_won  : 41.0\n\n```\n### 인사이트\n• 네트 플레이 성공률이 가장 중요한 지표\n• 세트 스코어와 포인트 차이가 핵심 요소\n• 에이스 관련 지표들의 높은 중요도\n• 시간 및 서버 변화는 상대적으로 낮은 중요도\n---\n## 6. 모델 활용 방안\n### 실시간 예측 시스템\n```python\ndef predict_live_momentum(models, feature_data, metadata, threshold=0.3):\n    \"\"\"\n    실시간 모멘텀 예측\n    - 모멘텀 값 예측 (회귀)\n    - 모멘텀 증가 확률 (분류)\n    - 임계값 기반 증가/감소 판단\n    \"\"\"\n\n```\n### 예측 결과 해석\n```plain text\n포인트 1: 모멘텀 0.560 | 예측: 감소/유지 | 확률: 32.6%\n포인트 2: 모멘텀 0.215 | 예측: 증가 | 확률: 75.6%\n포인트 3: 모멘텀 0.543 | 예측: 증가 | 확률: 78.2%\n\n```\n## 7. 결론 및 향후 계획\n• 임계값 적용\n• 데이터 eda 재진행\n• 모델 재학습 및 80% 향상시키기\n임계값 0.3: Acc 0.563, Prec 0.340, Rec 0.771, F1 0.472 (51,966개 증가 예측)\n임계값 0.4: Acc 0.735, Prec 0.391, Rec 0.084, F1 0.139 (4,922개 증가 예측)\n임계값 0.5: Acc 0.744, Prec 0.399, Rec 0.023, F1 0.043 (1,293개 증가 예측)"
  }
]