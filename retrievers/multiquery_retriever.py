#!/usr/bin/env python3
"""MultiQuery Retriever - LangChain ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥ì„ í†µí•œ ê²€ìƒ‰ ê°œì„ """

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain.chat_models import init_chat_model
from typing import List, Optional, Dict, Any
import os
from config.settings import AZURE_AI_CREDENTIAL, AZURE_AI_ENDPOINT
from retrievers.dense_retriever import get_dense_retriever


class MultiQueryRetriever(BaseRetriever):
    """
    ë©€í‹° ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„ - LLMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ í™•ì¥

    í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    LangChainì˜ BaseRetrieverë¥¼ ìƒì†í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
    """

    base_retriever: BaseRetriever
    """ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ (Dense, BM25, Ensemble ë“±)"""

    num_queries: int = 3
    """ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜ (ì›ë³¸ í¬í•¨)"""

    temperature: float = 0.7
    """LLM temperature ì„¤ì •"""

    llm_model: str = "azure_ai:gpt-4.1"
    """ì‚¬ìš©í•  LLM ëª¨ë¸"""

    class Config:
        arbitrary_types_allowed = True

    def __init__(
        self,
        base_retriever: BaseRetriever,
        num_queries: int = 3,
        temperature: float = 0.7,
        llm_model: str = "azure_ai:gpt-4.1",
        **kwargs
    ):
        """
        Args:
            base_retriever: ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ (Dense, BM25, Ensemble ë“±)
            num_queries: ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’: 3)
            temperature: LLM temperature (ê¸°ë³¸ê°’: 0.7)
            llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ (ê¸°ë³¸ê°’: azure_ai:gpt-4.1)
        """
        super().__init__(
            base_retriever=base_retriever,
            num_queries=num_queries,
            temperature=temperature,
            llm_model=llm_model,
            **kwargs
        )

        # Azure OpenAI ì„¤ì •
        if AZURE_AI_CREDENTIAL and AZURE_AI_ENDPOINT:
            os.environ['AZURE_AI_CREDENTIAL'] = AZURE_AI_CREDENTIAL
            os.environ['AZURE_AI_ENDPOINT'] = AZURE_AI_ENDPOINT

    def generate_queries(self, query: str) -> List[str]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì˜ ì¿¼ë¦¬ ìƒì„±

        Args:
            query: ì›ë³¸ ì¿¼ë¦¬

        Returns:
            í™•ì¥ëœ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ (ì›ë³¸ í¬í•¨)
        """
        prompt = f"""ë‹¹ì‹ ì€ ì •ë³´ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ {self.num_queries - 1}ê°œì˜ ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {query}

ìš”êµ¬ì‚¬í•­:
1. ê° ì§ˆë¬¸ì€ ì›ë³¸ ì§ˆë¬¸ê³¼ ê°™ì€ ì˜ë„ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤
2. ì„œë¡œ ë‹¤ë¥¸ í‘œí˜„, í‚¤ì›Œë“œ, ê´€ì ì„ ì‚¬ìš©í•˜ì„¸ìš”
3. ê° ì§ˆë¬¸ì€ í•œ ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”
4. ë²ˆí˜¸ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ ì—†ì´ ì§ˆë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”

ìƒì„±ëœ ì§ˆë¬¸ë“¤ (ê° ì¤„ì— í•˜ë‚˜ì”©):"""

        try:
            model = init_chat_model(
                self.llm_model,
                temperature=self.temperature,
                max_completion_tokens=300
            )
            response = model.invoke(prompt)

            # ì‘ë‹µì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
            generated_queries = [
                line.strip()
                for line in response.content.strip().split('\n')
                if line.strip() and not line.strip().startswith('#')
            ]

            # ì›ë³¸ ì¿¼ë¦¬ + ìƒì„±ëœ ì¿¼ë¦¬
            all_queries = [query] + generated_queries[:self.num_queries - 1]

            print(f"\n[MultiQuery] ìƒì„±ëœ ì¿¼ë¦¬:")
            for i, q in enumerate(all_queries, 1):
                print(f"  {i}. {q}")

            return all_queries

        except Exception as e:
            print(f"  âš ï¸ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"  â†’ ì›ë³¸ ì¿¼ë¦¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return [query]

    def _get_relevant_documents(
        self, query: str, *, run_manager: Optional[CallbackManagerForRetrieverRun] = None
    ) -> List[Document]:
        """
        LangChain í˜¸í™˜ ë©”ì„œë“œ: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            run_manager: ì½œë°± ë§¤ë‹ˆì €

        Returns:
            LangChain Document ë¦¬ìŠ¤íŠ¸
        """
        # ì¿¼ë¦¬ í™•ì¥
        queries = self.generate_queries(query)

        # ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
        all_results: Dict[str, Document] = {}

        for q in queries:
            # base_retrieverëŠ” invoke() ë©”ì„œë“œë¥¼ ì‚¬ìš©
            results = self.base_retriever.invoke(q)

            for doc in results:
                # chunk_idë¥¼ í‚¤ë¡œ ì‚¬ìš© (ì¤‘ë³µ ì œê±°)
                chunk_id = doc.metadata.get("chunk_id", id(doc))

                # ì´ë¯¸ ìˆëŠ” ê²½ìš°, ë” ë†’ì€ ìŠ¤ì½”ì–´ë¡œ ì—…ë°ì´íŠ¸
                # (ì—¬ëŸ¬ ì¿¼ë¦¬ì—ì„œ ë‚˜ì˜¨ ë¬¸ì„œëŠ” ë” ê´€ë ¨ì„±ì´ ë†’ë‹¤ê³  íŒë‹¨)
                if chunk_id not in all_results:
                    all_results[chunk_id] = doc
                # ê°™ì€ ë¬¸ì„œê°€ ì—¬ëŸ¬ ì¿¼ë¦¬ì—ì„œ ë‚˜ì™”ë‹¤ë©´ ì¤‘ìš”ë„ ì¦ê°€ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆìŒ
                # (í˜„ì¬ëŠ” ë‹¨ìˆœíˆ ì²« ë²ˆì§¸ ë°œê²¬ëœ ê²ƒì„ ìœ ì§€)

        # ì›ë˜ ìˆœì„œëŒ€ë¡œ ë°˜í™˜ (ë‚˜ì¤‘ì— ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ë„ ê°€ëŠ¥)
        sorted_results = list(all_results.values())

        print(f"  â†’ ì´ {len(all_results)}ê°œ ê³ ìœ  ë¬¸ì„œ ë°˜í™˜")

        return sorted_results

    def get_info(self) -> Dict[str, Any]:
        """ë¦¬íŠ¸ë¦¬ë²„ ì •ë³´ ë°˜í™˜"""
        return {
            "name": "MultiQueryRetriever",
            "type": self.__class__.__name__,
            "base_retriever": type(self.base_retriever).__name__,
            "num_queries": self.num_queries,
            "temperature": self.temperature,
            "llm_model": self.llm_model
        }


def get_multiquery_retriever(
    base_retriever: Optional[BaseRetriever] = None,
    num_queries: int = 3,
    temperature: float = 0.7,
    k: int = 5
) -> MultiQueryRetriever:
    """
    MultiQuery Retriever ìƒì„±

    Args:
        base_retriever: ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ (Noneì´ë©´ Dense Retriever ì‚¬ìš©)
        num_queries: ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜
        temperature: LLM temperature
        k: ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜

    Returns:
        MultiQueryRetriever ì¸ìŠ¤í„´ìŠ¤
    """
    # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ê°€ ì—†ìœ¼ë©´ Dense Retriever ì‚¬ìš©
    if base_retriever is None:
        base_retriever = get_dense_retriever(k=k)

    # MultiQuery Retriever ìƒì„±
    retriever = MultiQueryRetriever(
        base_retriever=base_retriever,
        num_queries=num_queries,
        temperature=temperature
    )

    return retriever


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("ğŸ” MultiQuery Retriever í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # Retriever ìƒì„± (Dense Retriever ê¸°ë°˜)
    retriever = get_multiquery_retriever(num_queries=3, k=5)

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "RAG ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ë™ì‘í•˜ë‚˜ìš”?",
        "ì„ë² ë”© ëª¨ë¸ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    ]

    for query in test_queries:
        print(f"\nğŸ“ Query: {query}")
        print("-" * 60)

        # invoke() ë©”ì„œë“œ ì‚¬ìš©
        results = retriever.invoke(query)

        for i, doc in enumerate(results, 1):
            print(f"\n[{i}] {doc.metadata.get('page_title', 'Unknown')}")
            print(f"    Section: {doc.metadata.get('section_title', 'N/A')}")
            print(f"    Content: {doc.page_content[:200]}...")

    print("\n" + "=" * 60)
    print("âœ… MultiQuery Retriever í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"\në¦¬íŠ¸ë¦¬ë²„ ì •ë³´: {retriever.get_info()}")
