당신은 RAG 기반 보고서 자동화 시스템을 평가하기 위한 **까다로운 QA 데이터**를 생성하는 전문가입니다.

아래 문서들을 바탕으로, **검색과 답변 생성이 어려운** 질문 1개와 해당 질문에 대한 상세한 기준 정답을 생성하세요.

[입력 문서]
{documents}

[질문 생성 규칙 - 까다로운 질문 만들기]

**난이도를 높이는 방법 (하나 이상 적용):**

1. **암묵적 표현 사용**
   - 문서의 핵심 키워드를 직접 사용하지 않기
   - 간접적이거나 유사한 표현으로 질문
   - 예: "테니스 모멘텀" → "경기 흐름 분석", "HMM" → "확률 모델"

2. **부분 정보만 제공**
   - 제목의 일부만 언급하거나 애매하게 표현
   - 예: "그 테니스 프로젝트...", "최근에 한 분석...", "저번에 본 결과..."

3. **복합적인 질문 (여러 문서 종합)**
   - 여러 문서의 내용을 비교, 대조, 종합하는 질문
   - 시간순 비교, 방법론 비교, 결과 비교 등
   - 예: "이전 방식과 개선된 방식 차이", "A 프로젝트랑 B 프로젝트 결과 비교"
   - **중요**: 여러 문서가 제공된 경우, 가능하면 2개 이상 문서를 참조하는 질문 생성

4. **구체적인 디테일 요구**
   - 숫자, 수치, 구체적인 방법론 언급
   - 예: "정확도가 몇 퍼센트였는지", "어떤 알고리즘을 사용했는지"

**질문 형식 (자연스러운 구어체 유지):**
  ✅ "[모호한 주제] 결과 어떻게 나왔어?"
  ✅ "[간접적 표현] 분석 보고서 만들어줘"
  ✅ "[부분 정보]... 있잖아, 그거 정리해줘"
  ✅ "[비교 요청] 차이점 분석해줘"
  ✅ "[여러 프로젝트] 종합해서 보고서 만들어줘"
  ✅ "[구체적 수치/방법] 어떻게 됐는지 보고서 작성해줘"

**절대 사용하면 안 되는 표현:**
  ❌ "설명하시오", "서술하시오", "논하시오"
  ❌ "이 문서에서", "문서에서"
  ❌ 50자 이상의 긴 질문

**제약사항:**
  - 질문은 10-40자 이내
  - 구어체 (친근한 말투)
  - 문서 제목의 핵심 키워드를 **직접 사용하지 않거나** 변형해서 사용
  - 검색이 어렵지만, 문서 내용으로는 답변 가능한 질문
  - 여러 문서가 제공된 경우, 가능하면 **2개 이상 문서를 참조**하는 질문

[답변 생성 규칙]
  - 제공된 문서 내용에만 근거하여 작성
  - 여러 문서를 참조하는 경우, 각 문서의 내용을 종합하여 작성
  - 핵심 내용, 결과, 시사점을 상세히 포함 (200-1500자)
  - 평가용 기준 정답으로 사용할 수 있도록 명확하게 작성
  - 문서에 없는 정보는 절대 추가하지 말 것
  - 까다로운 질문이지만, 답변은 문서 기반으로 정확하게

[좋은 예시 - 난이도 높은 질문]

예시 1 (암묵적 표현 - 단일 문서):
문서: "테니스 모멘텀 계산 및 시각화 결과"
{{
  "question": "경기 흐름 분석 결과 정리해줘",
  "ground_truth": "테니스 모멘텀 프로젝트에서는 HMM(Hidden Markov Model)으로 숨겨진 모멘텀 상태를 추정하고, EMA(Exponential Moving Average)로 값을 부드럽게 처리하여 최종 모멘텀 범위를 -2에서 +2로 달성했습니다. 전체 6,605개 경기 데이터에 적용한 히트맵 분석에서는 평균화 과정에서 개별 패턴이 소실되어 약한 상관관계만 나타났으나, 개별 경기 단위 분석으로 전환하면 모멘텀과 승리 확률 간 강한 상관관계를 관찰할 수 있어, 개별 경기 분석이 더 의미 있다고 결론지었습니다."
}}

예시 2 (여러 문서 종합):
문서 1: "테니스 모멘텀 데이터 전처리"
문서 2: "테니스 모멘텀 계산 및 시각화 결과"
{{
  "question": "테니스 관련 작업 전체 과정 정리해줘",
  "ground_truth": "테니스 모멘텀 프로젝트는 데이터 전처리와 모델 적용 두 단계로 진행되었습니다. 먼저 데이터 전처리 단계에서는 6,605개 경기의 원시 데이터를 수집하여 포인트별 득점, 실점, 에이스, 더블폴트 등의 이벤트를 정규화하고 결측치를 제거했습니다. 이후 모델 적용 단계에서는 HMM(Hidden Markov Model)으로 숨겨진 모멘텀 상태를 추정하고, EMA(Exponential Moving Average)로 값을 부드럽게 처리하여 -2에서 +2 범위의 모멘텀 값을 산출했습니다. 최종 결과 분석에서는 개별 경기 단위 분석이 전체 평균 분석보다 모멘텀-승률 간 상관관계를 더 명확히 보여준다는 결론을 도출했습니다."
}}

예시 3 (부분 정보 + 복합):
문서 1: "아쿠아누리 모델 학습 계획"
문서 2: "아쿠아누리 모델 학습 결과"
{{
  "question": "수중 프로젝트 계획이랑 실제 결과 비교해줘",
  "ground_truth": "아쿠아누리 프로젝트의 초기 계획에서는 YOLOv8 모델을 활용하여 mAP@0.5 목표 0.85 이상을 설정했으며, 1,000장 이상의 수중 이미지 데이터셋 구축을 계획했습니다. 실제 결과에서는 총 1,200장의 이미지로 데이터셋을 구성하여 계획 대비 20% 초과 달성했으며, 최종 mAP@0.5는 0.87로 목표를 상회했습니다. 특히 물고기 클래스는 계획한 0.85를 초과하여 0.92의 정확도를 기록했고, 실시간 추론 속도 또한 목표했던 25 FPS를 넘어 30 FPS를 달성하여 실제 수중 카메라 시스템 적용이 가능한 수준으로 개선되었습니다."
}}

예시 4 (구체적 방법론 비교 - 여러 문서):
문서 1: "줄넘기 수집데이터 전처리"
문서 2: "줄넘기 수집데이터 전처리 2차"
{{
  "question": "동작 인식 데이터 처리 진행 상황 정리해줘",
  "ground_truth": "줄넘기 프로젝트의 데이터 전처리는 1차와 2차로 나뉘어 진행되었습니다. 1차 전처리에서는 기본 동작(기본뛰기, 앞뛰기)을 중심으로 초기 프레임워크를 구축하고 관절 키포인트 추출 파이프라인을 설정했습니다. 2차 전처리에서는 34개 영상에 대한 추가 작업을 완료했으며, 현재 2단뛰기 2개, x자 동작 29개, 번갈아뛰기 24개 총 55개 영상이 처리 대기 중입니다. 각 단계에서 프레임 정규화(최소 32프레임), 노이즈 제거, 동작 구간 분할 작업을 수행하여 딥러닝 학습에 적합한 형태로 데이터를 변환했습니다."
}}

[나쁜 예시 - 너무 쉽거나 직접적인 질문]
❌ "테니스 모멘텀 계산 결과 보고서 만들어줘" (제목 그대로 사용)
❌ "아쿠아누리 모델 학습 결과 정리해줘" (제목 그대로 사용)
❌ "줄넘기 데이터 전처리 어떻게 됐어?" (키워드 그대로 사용)

[출력 형식]
반드시 아래 JSON 형식만 출력하세요. 다른 텍스트는 포함하지 마세요.

{{
  "question": "검색이 어려운 까다로운 사용자 질문",
  "ground_truth": "문서 기반의 정확하고 상세한 기준 답변",
  "referenced_docs": ["참조한 문서 제목들의 리스트"]
}}
