"""ì„ë² ë”© ìºì‹œ ìœ í‹¸ë¦¬í‹°

í‰ê°€ ì‹œ ë™ì¼í•œ ì§ˆë¬¸ì˜ ì„ë² ë”©ì„ ì¬ì‚¬ìš©í•˜ì—¬ API ë¹„ìš©ê³¼ ì‹œê°„ì„ ì ˆì•½í•©ë‹ˆë‹¤.
LangChainì˜ ìºì‹œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime
from langchain_classic.embeddings import CacheBackedEmbeddings
from langchain_classic.storage import LocalFileStore
from langchain_core.embeddings import Embeddings


class EmbeddingCache:
    """ì„ë² ë”© ê²°ê³¼ë¥¼ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹±í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, cache_dir: str = "data/evaluation/embedding_cache"):
        """
        Args:
            cache_dir: ìºì‹œ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "embeddings.json"
        self.metadata_file = self.cache_dir / "metadata.json"

        # ìºì‹œ ë¡œë“œ
        self.cache: Dict[str, List[float]] = self._load_cache()
        self.metadata: Dict[str, Any] = self._load_metadata()

        # í†µê³„
        self.hits = 0
        self.misses = 0

    def _load_cache(self) -> Dict[str, List[float]]:
        """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ (ìƒˆë¡œ ìƒì„±): {e}")
                return {}
        return {}

    def _load_metadata(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {}
        return {}

    def _generate_key(self, text: str, model: str = "default") -> str:
        """
        í…ìŠ¤íŠ¸ì™€ ëª¨ë¸ë¡œë¶€í„° ìºì‹œ í‚¤ ìƒì„±

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            SHA256 í•´ì‹œ ê¸°ë°˜ ìºì‹œ í‚¤
        """
        # ëª¨ë¸ëª… + í…ìŠ¤íŠ¸ë¡œ ê³ ìœ  í‚¤ ìƒì„±
        key_input = f"{model}:{text}"
        return hashlib.sha256(key_input.encode('utf-8')).hexdigest()

    def get(self, text: str, model: str = "default") -> Optional[List[float]]:
        """
        ìºì‹œì—ì„œ ì„ë² ë”© ì¡°íšŒ

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            ìºì‹œëœ ì„ë² ë”© ë²¡í„° ë˜ëŠ” None
        """
        key = self._generate_key(text, model)
        if key in self.cache:
            self.hits += 1
            return self.cache[key]

        self.misses += 1
        return None

    def set(self, text: str, embedding: List[float], model: str = "default"):
        """
        ì„ë² ë”©ì„ ìºì‹œì— ì €ì¥

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            embedding: ì„ë² ë”© ë²¡í„°
            model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        key = self._generate_key(text, model)
        self.cache[key] = embedding

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if key not in self.metadata:
            self.metadata[key] = {
                "text_preview": text[:100],  # ë””ë²„ê¹…ìš©
                "model": model,
                "created_at": datetime.now().isoformat(),
                "dimension": len(embedding)
            }

    def get_batch(
        self,
        texts: List[str],
        model: str = "default"
    ) -> tuple[List[Optional[List[float]]], List[int]]:
        """
        ë°°ì¹˜ë¡œ ìºì‹œ ì¡°íšŒ

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            (ì„ë² ë”© ë¦¬ìŠ¤íŠ¸, ìºì‹œ ë¯¸ìŠ¤ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸)
            - ì„ë² ë”© ë¦¬ìŠ¤íŠ¸: ìºì‹œëœ ì„ë² ë”© ë˜ëŠ” None
            - ë¯¸ìŠ¤ ì¸ë±ìŠ¤: ìºì‹œì— ì—†ëŠ” í…ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤
        """
        embeddings = []
        miss_indices = []

        for i, text in enumerate(texts):
            embedding = self.get(text, model)
            embeddings.append(embedding)
            if embedding is None:
                miss_indices.append(i)

        return embeddings, miss_indices

    def set_batch(
        self,
        texts: List[str],
        embeddings: List[List[float]],
        model: str = "default"
    ):
        """
        ë°°ì¹˜ë¡œ ìºì‹œì— ì €ì¥

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            embeddings: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        for text, embedding in zip(texts, embeddings):
            self.set(text, embedding, model)

    def save(self):
        """ìºì‹œë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            # ìºì‹œ ì €ì¥
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False)

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata["last_updated"] = datetime.now().isoformat()
            self.metadata["total_entries"] = len(self.cache)
            self.metadata["stats"] = {
                "hits": self.hits,
                "misses": self.misses,
                "hit_rate": self.hits / (self.hits + self.misses) if (self.hits + self.misses) > 0 else 0
            }

            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, indent=2, ensure_ascii=False)

            return True
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def clear(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache = {}
        self.metadata = {}
        self.hits = 0
        self.misses = 0

        if self.cache_file.exists():
            self.cache_file.unlink()
        if self.metadata_file.exists():
            self.metadata_file.unlink()

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self.hits + self.misses
        hit_rate = self.hits / total_requests if total_requests > 0 else 0

        return {
            "total_entries": len(self.cache),
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate,
            "cache_size_mb": self.cache_file.stat().st_size / (1024 * 1024) if self.cache_file.exists() else 0
        }

    def print_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        stats = self.get_stats()
        print("\nğŸ“Š ì„ë² ë”© ìºì‹œ í†µê³„:")
        print(f"  - ì´ ìºì‹œ í•­ëª©: {stats['total_entries']}")
        print(f"  - ìºì‹œ íˆíŠ¸: {stats['hits']}")
        print(f"  - ìºì‹œ ë¯¸ìŠ¤: {stats['misses']}")
        print(f"  - íˆíŠ¸ìœ¨: {stats['hit_rate']*100:.1f}%")
        print(f"  - ìºì‹œ í¬ê¸°: {stats['cache_size_mb']:.2f} MB")


class CachedEmbedder:
    """LangChainì˜ CacheBackedEmbeddingsë¥¼ ì‚¬ìš©í•˜ëŠ” ì„ë² ë”© ìºì‹œ ë˜í¼"""

    def __init__(self, embedder, cache: Optional[EmbeddingCache] = None, model_name: str = "default"):
        """
        Args:
            embedder: ì›ë³¸ ì„ë² ë”© ëª¨ë¸ (LangChain Embeddings ì¸í„°í˜ì´ìŠ¤)
            cache: ë ˆê±°ì‹œ ìºì‹œ ê°ì²´ (í†µê³„ìš©, ì‹¤ì œë¡œëŠ” LocalFileStore ì‚¬ìš©)
            model_name: ëª¨ë¸ ì´ë¦„ (ìºì‹œ í‚¤ ìƒì„±ì— ì‚¬ìš©)
        """
        self.embedder = embedder
        self.cache = cache or EmbeddingCache()
        self.model_name = model_name

        # LangChainì˜ LocalFileStore ìºì‹œ ë°±ì—”ë“œ ìƒì„±
        cache_dir = str(self.cache.cache_dir / "langchain_store")
        self.file_store = LocalFileStore(cache_dir)

        # CacheBackedEmbeddings ìƒì„±
        self.cached_embedder = CacheBackedEmbeddings.from_bytes_store(
            underlying_embeddings=embedder,
            document_embedding_cache=self.file_store,
            namespace=model_name
        )

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """
        LangChain ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        # LangChainì´ ìë™ìœ¼ë¡œ ìºì‹œ í™•ì¸ ë° ì €ì¥
        embeddings = self.cached_embedder.embed_documents(texts)

        # í†µê³„ ì—…ë°ì´íŠ¸ (ëŒ€ëµì )
        self.cache.misses += len(texts)  # ì‹¤ì œë¡œëŠ” LangChainì´ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬

        return embeddings

    def embed_query(self, query: str) -> List[float]:
        """
        ë‹¨ì¼ ì¿¼ë¦¬ ì„ë² ë”© (LangChain ìºì‹œ ì‚¬ìš©)

        Args:
            query: ì„ë² ë”©í•  ì¿¼ë¦¬

        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        # LangChainì˜ ìºì‹œëœ ì¿¼ë¦¬ ì„ë² ë”©
        embedding = self.cached_embedder.embed_query(query)
        return embedding

    def save_cache(self):
        """ìºì‹œë¥¼ íŒŒì¼ì— ì €ì¥ (LangChainì€ ìë™ ì €ì¥)"""
        # LangChainì˜ LocalFileStoreëŠ” ìë™ìœ¼ë¡œ ì €ì¥ë¨
        # ë ˆê±°ì‹œ ìºì‹œ í†µê³„ ì €ì¥
        return self.cache.save()

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        return self.cache.get_stats()

    def print_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        self.cache.print_stats()
