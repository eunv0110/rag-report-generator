"""ì„ë² ë”© ìºì‹œ ìœ í‹¸ë¦¬í‹°

í‰ê°€ ì‹œ ë™ì¼í•œ ì§ˆë¬¸ì˜ ì„ë² ë”©ì„ ì¬ì‚¬ìš©í•˜ì—¬ API ë¹„ìš©ê³¼ ì‹œê°„ì„ ì ˆì•½í•©ë‹ˆë‹¤.
"""

import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime


class EmbeddingCache:
    """ì„ë² ë”© ê²°ê³¼ë¥¼ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹±í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, cache_dir: str = "data/evaluation/embedding_cache"):
        """
        Args:
            cache_dir: ìºì‹œ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_file = self.cache_dir / "embeddings.json"
        self.metadata_file = self.cache_dir / "metadata.json"

        # ìºì‹œ ë¡œë“œ
        self.cache: Dict[str, List[float]] = self._load_cache()
        self.metadata: Dict[str, Any] = self._load_metadata()

        # í†µê³„
        self.hits = 0
        self.misses = 0

    def _load_cache(self) -> Dict[str, List[float]]:
        """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ (ìƒˆë¡œ ìƒì„±): {e}")
                return {}
        return {}

    def _load_metadata(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {}
        return {}

    def _generate_key(self, text: str, model: str = "default") -> str:
        """
        í…ìŠ¤íŠ¸ì™€ ëª¨ë¸ë¡œë¶€í„° ìºì‹œ í‚¤ ìƒì„±

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            SHA256 í•´ì‹œ ê¸°ë°˜ ìºì‹œ í‚¤
        """
        # ëª¨ë¸ëª… + í…ìŠ¤íŠ¸ë¡œ ê³ ìœ  í‚¤ ìƒì„±
        key_input = f"{model}:{text}"
        return hashlib.sha256(key_input.encode('utf-8')).hexdigest()

    def get(self, text: str, model: str = "default") -> Optional[List[float]]:
        """
        ìºì‹œì—ì„œ ì„ë² ë”© ì¡°íšŒ

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            ìºì‹œëœ ì„ë² ë”© ë²¡í„° ë˜ëŠ” None
        """
        key = self._generate_key(text, model)
        if key in self.cache:
            self.hits += 1
            return self.cache[key]

        self.misses += 1
        return None

    def set(self, text: str, embedding: List[float], model: str = "default"):
        """
        ì„ë² ë”©ì„ ìºì‹œì— ì €ì¥

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            embedding: ì„ë² ë”© ë²¡í„°
            model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        key = self._generate_key(text, model)
        self.cache[key] = embedding

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if key not in self.metadata:
            self.metadata[key] = {
                "text_preview": text[:100],  # ë””ë²„ê¹…ìš©
                "model": model,
                "created_at": datetime.now().isoformat(),
                "dimension": len(embedding)
            }

    def get_batch(
        self,
        texts: List[str],
        model: str = "default"
    ) -> tuple[List[Optional[List[float]]], List[int]]:
        """
        ë°°ì¹˜ë¡œ ìºì‹œ ì¡°íšŒ

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…

        Returns:
            (ì„ë² ë”© ë¦¬ìŠ¤íŠ¸, ìºì‹œ ë¯¸ìŠ¤ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸)
            - ì„ë² ë”© ë¦¬ìŠ¤íŠ¸: ìºì‹œëœ ì„ë² ë”© ë˜ëŠ” None
            - ë¯¸ìŠ¤ ì¸ë±ìŠ¤: ìºì‹œì— ì—†ëŠ” í…ìŠ¤íŠ¸ì˜ ì¸ë±ìŠ¤
        """
        embeddings = []
        miss_indices = []

        for i, text in enumerate(texts):
            embedding = self.get(text, model)
            embeddings.append(embedding)
            if embedding is None:
                miss_indices.append(i)

        return embeddings, miss_indices

    def set_batch(
        self,
        texts: List[str],
        embeddings: List[List[float]],
        model: str = "default"
    ):
        """
        ë°°ì¹˜ë¡œ ìºì‹œì— ì €ì¥

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            embeddings: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
            model: ì„ë² ë”© ëª¨ë¸ëª…
        """
        for text, embedding in zip(texts, embeddings):
            self.set(text, embedding, model)

    def save(self):
        """ìºì‹œë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            # ìºì‹œ ì €ì¥
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False)

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata["last_updated"] = datetime.now().isoformat()
            self.metadata["total_entries"] = len(self.cache)
            self.metadata["stats"] = {
                "hits": self.hits,
                "misses": self.misses,
                "hit_rate": self.hits / (self.hits + self.misses) if (self.hits + self.misses) > 0 else 0
            }

            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, indent=2, ensure_ascii=False)

            return True
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def clear(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache = {}
        self.metadata = {}
        self.hits = 0
        self.misses = 0

        if self.cache_file.exists():
            self.cache_file.unlink()
        if self.metadata_file.exists():
            self.metadata_file.unlink()

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self.hits + self.misses
        hit_rate = self.hits / total_requests if total_requests > 0 else 0

        return {
            "total_entries": len(self.cache),
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate,
            "cache_size_mb": self.cache_file.stat().st_size / (1024 * 1024) if self.cache_file.exists() else 0
        }

    def print_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        stats = self.get_stats()
        print("\nğŸ“Š ì„ë² ë”© ìºì‹œ í†µê³„:")
        print(f"  - ì´ ìºì‹œ í•­ëª©: {stats['total_entries']}")
        print(f"  - ìºì‹œ íˆíŠ¸: {stats['hits']}")
        print(f"  - ìºì‹œ ë¯¸ìŠ¤: {stats['misses']}")
        print(f"  - íˆíŠ¸ìœ¨: {stats['hit_rate']*100:.1f}%")
        print(f"  - ìºì‹œ í¬ê¸°: {stats['cache_size_mb']:.2f} MB")


class CachedEmbedder:
    """ì„ë² ë”© ëª¨ë¸ì„ ë˜í•‘í•˜ì—¬ ìºì‹œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, embedder, cache: Optional[EmbeddingCache] = None, model_name: str = "default"):
        """
        Args:
            embedder: ì›ë³¸ ì„ë² ë”© ëª¨ë¸ (embed_texts ë©”ì„œë“œ í•„ìš”)
            cache: ì„ë² ë”© ìºì‹œ ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
            model_name: ëª¨ë¸ ì´ë¦„ (ìºì‹œ í‚¤ ìƒì„±ì— ì‚¬ìš©)
        """
        self.embedder = embedder
        self.cache = cache or EmbeddingCache()
        self.model_name = model_name

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """
        ìºì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        # 1. ìºì‹œì—ì„œ ì¡°íšŒ
        embeddings, miss_indices = self.cache.get_batch(texts, self.model_name)

        # 2. ìºì‹œ ë¯¸ìŠ¤ í•­ëª©ë§Œ ì„ë² ë”© ìƒì„±
        if miss_indices:
            miss_texts = [texts[i] for i in miss_indices]
            print(f"  ğŸ’¾ ìºì‹œ ë¯¸ìŠ¤ {len(miss_indices)}ê°œ í•­ëª© ì„ë² ë”© ìƒì„± ì¤‘...")

            new_embeddings = self.embedder.embed_texts(miss_texts)

            # 3. ìƒˆë¡œ ìƒì„±í•œ ì„ë² ë”©ì„ ìºì‹œì— ì €ì¥
            self.cache.set_batch(miss_texts, new_embeddings, self.model_name)

            # 4. ê²°ê³¼ ë³‘í•©
            for i, embedding in zip(miss_indices, new_embeddings):
                embeddings[i] = embedding
        else:
            print(f"  âœ… ëª¨ë“  í•­ëª©({len(texts)}ê°œ)ì´ ìºì‹œì—ì„œ ì¡°íšŒë¨")

        return embeddings

    def embed_query(self, query: str) -> List[float]:
        """
        ë‹¨ì¼ ì¿¼ë¦¬ ì„ë² ë”© (ìºì‹œ ì‚¬ìš©)

        Args:
            query: ì„ë² ë”©í•  ì¿¼ë¦¬

        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        # ìºì‹œ ì¡°íšŒ
        cached_embedding = self.cache.get(query, self.model_name)
        if cached_embedding is not None:
            return cached_embedding

        # ìºì‹œ ë¯¸ìŠ¤ - ìƒˆë¡œ ìƒì„±
        if hasattr(self.embedder, 'embed_query'):
            embedding = self.embedder.embed_query(query)
        else:
            embedding = self.embedder.embed_texts([query])[0]

        # ìºì‹œì— ì €ì¥
        self.cache.set(query, embedding, self.model_name)

        return embedding

    def save_cache(self):
        """ìºì‹œë¥¼ íŒŒì¼ì— ì €ì¥"""
        return self.cache.save()

    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        return self.cache.get_stats()

    def print_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        self.cache.print_stats()
