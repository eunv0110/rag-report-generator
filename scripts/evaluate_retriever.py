#!/usr/bin/env python3
"""í†µí•© RAG ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ì˜ˆì‹œ:
    # BM25 ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€
    python scripts/evaluate.py --retriever bm25_korean

    # Dense ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€
    python scripts/evaluate.py --retriever dense

    # RRF Ensemble ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€
    python scripts/evaluate.py --retriever ensemble_rrf

    # RRF + LongContext ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€
    python scripts/evaluate.py --retriever ensemble_rrf_longcontext

    # MultiQuery ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€ (ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„: ensemble)
    python scripts/evaluate.py --retriever multiquery --base-retriever ensemble --num-queries 3

    # RRF + MultiQuery í‰ê°€
    python scripts/evaluate.py --retriever multiquery --base-retriever ensemble_rrf --num-queries 3

    # RRF + LongContext + MultiQuery í‰ê°€
    python scripts/evaluate.py --retriever multiquery --base-retriever ensemble_rrf_longcontext --num-queries 3

    # QueryRewrite ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€ (ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„: ensemble_rrf)
    python scripts/evaluate.py --retriever query_rewrite --base-retriever ensemble_rrf

    # QueryRewrite + Dense í‰ê°€
    python scripts/evaluate.py --retriever query_rewrite --base-retriever dense

    # TimeWeighted ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€
    python scripts/evaluate.py --retriever time_weighted --decay-rate 0.01

    # RRF + TimeWeighted í‰ê°€
    python scripts/evaluate.py --retriever ensemble_rrf_timeweighted --decay-rate 0.01

    # S11: Summary-Level í‰ê°€
    python scripts/evaluate.py --retriever summary

    # S12: Mixed Retrieval í‰ê°€
    python scripts/evaluate.py --retriever mixed

    # RRF + Summary (S11) í‰ê°€
    python scripts/evaluate.py --retriever ensemble_rrf_summary

    # RRF + Mixed (S12) í‰ê°€
    python scripts/evaluate.py --retriever ensemble_rrf_mixed

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬íŠ¸ë¦¬ë²„ ëª©ë¡ í™•ì¸
    python scripts/evaluate.py --list-retrievers
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import time
import os
from datetime import datetime
from typing import List, Dict, Any, Optional
from qdrant_client import QdrantClient
from langchain.chat_models import init_chat_model

from config.settings import (
    QDRANT_PATH,
    AZURE_AI_CREDENTIAL,
    AZURE_AI_ENDPOINT,
    MODEL_CONFIG
)
from retrievers.bm25_retriever import BM25Retriever
from retrievers.dense_retriever import DenseRetriever
from retrievers.ensemble_retriever import EnsembleRetriever
from retrievers.ensemble_longcontext_retriever import EnsembleLongContextRetriever
from retrievers.multiquery_retriever import MultiQueryRetriever
from retrievers.time_weighted_retriever import TimeWeightedRetriever
from retrievers.raptor_retriever import RaptorRetriever
from retrievers.summary_retriever import SummaryRetriever
from retrievers.mixed_retriever import MixedRetriever
from retrievers.query_rewrite_retriever import QueryRewriteRetriever
from utils.langfuse_utils import get_langfuse_client
from utils.embedding_cache import EmbeddingCache, CachedEmbedder
from models.embeddings.factory import get_embedder

# ìƒìˆ˜ ì •ì˜
DEFAULT_DATASET_PATH = "/home/work/rag/Project/rag-report-generator/data/evaluation/merged_qa_dataset.json"
DEFAULT_NUM_CONTEXTS_FOR_ANSWER = 5
DEFAULT_TEMPERATURE = 0.1
DEFAULT_MAX_TOKENS = 500
DEFAULT_TOP_K = 10
DEFAULT_NUM_QUERIES = 3
DEFAULT_DECAY_RATE = 0.01

SYSTEM_PROMPT_FILE = "prompts/templates/evaluation/system_prompt.txt"
ANSWER_PROMPT_FILE = "prompts/templates/evaluation/answer_generation_prompt.txt"

# ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…
AVAILABLE_RETRIEVERS = {
    "bm25_basic": "BM25 ë¦¬íŠ¸ë¦¬ë²„ (ê¸°ë³¸)",
    "bm25_korean": "BM25 ë¦¬íŠ¸ë¦¬ë²„ (í•œêµ­ì–´ í† í¬ë‚˜ì´ì €)",
    "dense": "Dense ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„",
    "ensemble_rrf": "RRF Ensemble (BM25 + Dense)",
    "ensemble_rrf_longcontext": "RRF + LongContextReorder (BM25 + Dense)",
    "ensemble_rrf_timeweighted": "RRF + TimeWeighted (BM25 + TimeWeighted)",
    "ensemble_rrf_timeweighted_longcontext": "RRF + TimeWeighted + LongContext (BM25 + TimeWeighted)",
    "multiquery": "MultiQuery ë¦¬íŠ¸ë¦¬ë²„ (ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìœ„ì— ë˜í•‘)",
    "query_rewrite": "QueryRewrite ë¦¬íŠ¸ë¦¬ë²„ (ì¿¼ë¦¬ ìµœì í™” + ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„)",
    "time_weighted": "TimeWeighted ë¦¬íŠ¸ë¦¬ë²„",
    "raptor": "RAPTOR Tree ë¦¬íŠ¸ë¦¬ë²„ (ê³„ì¸µì  ë¬¸ì„œ êµ¬ì¡°)",
    "raptor_refine": "RAPTOR Tree ë¦¬íŠ¸ë¦¬ë²„ with Refine Summarizer (ë¬¸ë§¥ ì¼ê´€ì„± ê°•í™”)",
    "ensemble_rrf_raptor": "RRF Ensemble (BM25 + Dense + RAPTOR)",
    "ensemble_rrf_raptor_refine": "RRF Ensemble (BM25 + Dense + RAPTOR Refine)",
    "ensemble_rrf_summary": "S11: RRF Ensemble (BM25 + Dense[notion_summary])",
    "ensemble_rrf_mixed": "S12: RRF Ensemble (BM25 + Dense[notion_mixed])",
}


def generate_version_tag(retriever_name: str, version: str = "v1") -> str:
    """ë²„ì „ íƒœê·¸ ìƒì„±"""
    date_str = datetime.now().strftime("%Y%m%d")
    return f"{retriever_name}_{date_str}_{version}"


def load_prompt(prompt_file: str) -> str:
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
    prompt_path = Path(__file__).parent.parent / prompt_file
    if not prompt_path.exists():
        raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")

    with open(prompt_path, "r", encoding="utf-8") as f:
        return f.read().strip()


def load_evaluation_dataset(file_path: str) -> List[Dict[str, Any]]:
    """í‰ê°€ìš© ë°ì´í„°ì…‹ ë¡œë“œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_llm_answer(question: str, contexts: List[str]) -> str:
    """LLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±"""
    if not AZURE_AI_CREDENTIAL or not AZURE_AI_ENDPOINT:
        return "Azure OpenAI ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."

    os.environ['AZURE_AI_CREDENTIAL'] = AZURE_AI_CREDENTIAL
    os.environ['AZURE_AI_ENDPOINT'] = AZURE_AI_ENDPOINT

    answer_prompt_template = load_prompt(ANSWER_PROMPT_FILE)
    context_text = "\n\n".join(contexts[:DEFAULT_NUM_CONTEXTS_FOR_ANSWER]) if contexts else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    prompt = answer_prompt_template.replace("{{context}}", context_text).replace("{{question}}", question)

    try:
        model = init_chat_model(
            "azure_ai:gpt-4.1",
            temperature=DEFAULT_TEMPERATURE,
            max_completion_tokens=DEFAULT_MAX_TOKENS
        )
        response = model.invoke(prompt)
        return response.content
    except Exception as e:
        error_msg = f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        print(f"  âš ï¸ LLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return error_msg


def create_trace_and_generation(
    langfuse,
    retriever_name: str,
    question: str,
    contexts: List[str],
    answer: str,
    ground_truth: str,
    context_metadata: List[Dict],
    item_metadata: Dict,
    total_time: float,
    idx: int,
    context_page_id: Optional[str] = None,
    version_tag: str = "v1",
    retriever_tags: List[str] = None
) -> str:
    """Langfuse Traceì™€ Generation ìƒì„±"""
    context_text = "\n\n---\n\n".join(contexts) if contexts else ""

    if retriever_tags is None:
        retriever_tags = []

    all_tags = [
        f"{retriever_name}_{version_tag}",
        version_tag,
        "evaluation"
    ] + retriever_tags

    with langfuse.start_as_current_observation(
        as_type='generation',
        name=f"generation_{retriever_name}_{version_tag}",
        model="gpt-4.1",
        input={
            "question": question,
            "context": context_text
        },
        output={
            "answer": answer
        },
        metadata={
            "ground_truth": ground_truth,
            "contexts": contexts,
            "context_metadata": context_metadata,
            "retriever_type": retriever_name,
            "version": version_tag,
            "retriever_tags": retriever_tags
        }
    ) as generation:
        trace_id = generation.trace_id

        langfuse.update_current_trace(
            name=f"eval_{retriever_name}_{version_tag}_q{idx}",
            tags=all_tags,
            input={
                "question": question,
                "context": context_text
            },
            output={
                "answer": answer
            },
            metadata={
                "retriever": retriever_name,
                "version": version_tag,
                "total_time_ms": total_time * 1000,
                "num_retrieved_contexts": len(contexts),
                "context_page_id": context_page_id,
                "question_id": idx,
                "category": item_metadata.get("category", "unknown"),
                "difficulty": item_metadata.get("difficulty", "unknown"),
                "retriever_components": retriever_tags
            }
        )

    print(f"\n[DEBUG] Trace {idx}:")
    print(f"  - ID: {trace_id}")
    print(f"  - Question: {question[:50]}...")
    print(f"  - Context length: {len(context_text)} chars")
    print(f"  - Answer length: {len(answer)} chars")

    return trace_id


def add_retrieval_quality_score(langfuse, trace_id: str, context_metadata: List[Dict]):
    """ê²€ìƒ‰ í’ˆì§ˆ ìŠ¤ì½”ì–´ ì¶”ê°€"""
    if not context_metadata:
        return

    avg_score = sum(m["score"] for m in context_metadata) / len(context_metadata)
    langfuse.create_score(
        trace_id=trace_id,
        name="retrieval_quality",
        value=avg_score,
        comment=f"Average retrieval score from {len(context_metadata)} contexts"
    )


def evaluate_single_query(
    retriever,
    item: Dict[str, Any],
    langfuse,
    idx: int,
    top_k: int,
    base_version: str = "v1",
    retriever_tags: List[str] = None
) -> Dict[str, Any]:
    """ë‹¨ì¼ ì¿¼ë¦¬ í‰ê°€"""
    question = item["question"]
    ground_truth = item["ground_truth"]
    context_page_id = item.get("context_page_id")
    item_metadata = item.get("metadata", {})

    version_tag = generate_version_tag(retriever.name, base_version)
    start_time = time.time()

    # ê²€ìƒ‰ ìˆ˜í–‰
    search_results = retriever.search(question, top_k=top_k)
    contexts = [result.combined_text for result in search_results]

    if not contexts:
        print(f"  âš ï¸ [{idx}] No contexts found for question!")
        contexts = ["ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."]

    context_metadata = [
        {
            "score": result.score,
            "page_title": result.page_title,
            "section_title": result.section_title,
            "chunk_id": result.chunk_id
        }
        for result in search_results
    ]

    # LLM ë‹µë³€ ìƒì„±
    answer = generate_llm_answer(question, contexts)

    if not answer or answer.startswith("ë‹µë³€ ìƒì„± ì‹¤íŒ¨") or answer.startswith("Azure OpenAI ì„¤ì •"):
        print(f"  âš ï¸ [{idx}] LLM answer generation failed!")
        if not answer:
            answer = "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    total_time = time.time() - start_time

    # Langfuse Trace & Generation
    trace_id = create_trace_and_generation(
        langfuse=langfuse,
        retriever_name=retriever.name,
        question=question,
        contexts=contexts,
        answer=answer,
        ground_truth=ground_truth,
        context_metadata=context_metadata,
        item_metadata=item_metadata,
        total_time=total_time,
        idx=idx,
        context_page_id=context_page_id,
        version_tag=version_tag,
        retriever_tags=retriever_tags
    )

    # ê²€ìƒ‰ í’ˆì§ˆ ìŠ¤ì½”ì–´ ì¶”ê°€
    add_retrieval_quality_score(langfuse, trace_id, context_metadata)

    print(f"  [{idx}] {question[:50]}... ({len(contexts)}ê°œ ë¬¸ì„œ, {total_time*1000:.0f}ms)")

    return {
        "question": question,
        "answer": answer,
        "ground_truth": ground_truth,
        "num_contexts": len(contexts),
        "time": total_time,
        "trace_id": trace_id
    }


def evaluate_retriever(
    retriever,
    eval_data: List[Dict[str, Any]],
    langfuse,
    top_k: int = DEFAULT_TOP_K,
    base_version: str = "v1",
    retriever_tags: List[str] = None
) -> Dict[str, Any]:
    """ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€"""
    print(f"\n{'=' * 60}")
    print(f"ğŸ” {retriever.name} í‰ê°€ ì¤‘...")
    print(f"{'=' * 60}")

    stats = {
        "total_queries": len(eval_data),
        "total_time": 0,
        "evaluations": []
    }

    for idx, item in enumerate(eval_data, 1):
        eval_result = evaluate_single_query(
            retriever=retriever,
            item=item,
            langfuse=langfuse,
            idx=idx,
            top_k=top_k,
            base_version=base_version,
            retriever_tags=retriever_tags
        )

        stats["evaluations"].append(eval_result)
        stats["total_time"] += eval_result["time"]

    stats["avg_time"] = stats["total_time"] / stats["total_queries"]
    stats["avg_contexts"] = sum(e["num_contexts"] for e in stats["evaluations"]) / stats["total_queries"]

    return stats


def create_retriever(
    retriever_type: str,
    qdrant_client: QdrantClient,
    embedding_cache: Optional[EmbeddingCache] = None,
    base_retriever_type: str = "ensemble_rrf",
    num_queries: int = DEFAULT_NUM_QUERIES,
    decay_rate: float = DEFAULT_DECAY_RATE
):
    """
    ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜

    Args:
        retriever_type: ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…
        qdrant_client: Qdrant í´ë¼ì´ì–¸íŠ¸
        embedding_cache: ì„ë² ë”© ìºì‹œ (Dense ë¦¬íŠ¸ë¦¬ë²„ìš©)
        base_retriever_type: MultiQueryì˜ ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…
        num_queries: MultiQueryì—ì„œ ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜
        decay_rate: TimeWeighted ë¦¬íŠ¸ë¦¬ë²„ì˜ decay rate

    Returns:
        (retriever, retriever_tags)
    """
    retriever_tags = []

    # ì„ë² ë” ìƒì„± (Dense ë¦¬íŠ¸ë¦¬ë²„ í•„ìš”ì‹œ)
    def get_cached_embedder():
        base_embedder = get_embedder()
        if embedding_cache:
            # ì„¤ì • íŒŒì¼ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
            embedding_model = MODEL_CONFIG.get('embeddings', {}).get('model', 'text-embedding-3-large')
            return CachedEmbedder(base_embedder, embedding_cache, model_name=embedding_model)
        return base_embedder

    # BM25 ë¦¬íŠ¸ë¦¬ë²„
    if retriever_type == "bm25_basic":
        retriever = BM25Retriever(qdrant_client, use_korean_tokenizer=False)
        retriever_tags = ["bm25"]

    elif retriever_type == "bm25_korean":
        retriever = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        retriever_tags = ["bm25", "korean"]

    # Dense ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "dense":
        embedder = get_cached_embedder()
        retriever = DenseRetriever(qdrant_client, embedder=embedder)
        retriever_tags = ["dense"]

    # RRF Ensemble
    elif retriever_type == "ensemble_rrf":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense = DenseRetriever(qdrant_client, embedder=embedder)
        retriever = EnsembleRetriever(
            retrievers=[bm25, dense],
            name="ensemble_rrf"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "dense"]

    # RRF + LongContext
    elif retriever_type == "ensemble_rrf_longcontext":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense = DenseRetriever(qdrant_client, embedder=embedder)
        retriever = EnsembleLongContextRetriever(
            retrievers=[bm25, dense],
            name="ensemble_rrf_longcontext"
        )
        retriever_tags = ["ensemble", "rrf", "longcontext", "bm25", "dense"]

    # TimeWeighted ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "time_weighted":
        embedder = get_cached_embedder()
        retriever = TimeWeightedRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            decay_rate=decay_rate,
            name=f"time_weighted_decay{decay_rate}"
        )
        retriever_tags = ["time_weighted", f"decay_{decay_rate}"]

    # RRF + TimeWeighted
    elif retriever_type == "ensemble_rrf_timeweighted":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        tw = TimeWeightedRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            decay_rate=decay_rate,
            name=f"time_weighted_decay{decay_rate}"
        )
        retriever = EnsembleRetriever(
            retrievers=[bm25, tw],
            name=f"ensemble_rrf_timeweighted_{decay_rate}"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "time_weighted", f"decay_{decay_rate}"]

    # RRF + TimeWeighted + LongContext
    elif retriever_type == "ensemble_rrf_timeweighted_longcontext":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        tw = TimeWeightedRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            decay_rate=decay_rate,
            name=f"time_weighted_decay{decay_rate}"
        )
        retriever = EnsembleLongContextRetriever(
            retrievers=[bm25, tw],
            name=f"ensemble_rrf_timeweighted_longcontext_{decay_rate}"
        )
        retriever_tags = ["ensemble", "rrf", "longcontext", "bm25", "time_weighted", f"decay_{decay_rate}"]

    # MultiQuery ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "multiquery":
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever, base_tags = create_retriever(
            base_retriever_type,
            qdrant_client,
            embedding_cache,
            decay_rate=decay_rate
        )
        retriever = MultiQueryRetriever(
            base_retriever=base_retriever,
            num_queries=num_queries,
            name=f"multiquery_{base_retriever.name}"
        )
        retriever_tags = ["multiquery", f"num_queries_{num_queries}"] + base_tags

    # RAPTOR ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "raptor":
        embedder = get_cached_embedder()
        retriever = RaptorRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_raptor"
        )
        retriever_tags = ["raptor", "tree", "hierarchical"]

    # RAPTOR Refine ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "raptor_refine":
        embedder = get_cached_embedder()
        retriever = RaptorRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_raptor_refine",
            name="raptor_refine"
        )
        retriever_tags = ["raptor", "tree", "hierarchical", "refine"]

    # RRF + RAPTOR
    elif retriever_type == "ensemble_rrf_raptor":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense = DenseRetriever(qdrant_client, embedder=embedder)
        raptor = RaptorRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_raptor"
        )
        retriever = EnsembleRetriever(
            retrievers=[bm25, dense, raptor],
            name="ensemble_rrf_raptor"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "dense", "raptor"]

    # RRF + RAPTOR Refine
    elif retriever_type == "ensemble_rrf_raptor_refine":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense = DenseRetriever(qdrant_client, embedder=embedder)
        raptor = RaptorRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_raptor_refine",
            name="raptor_refine"
        )
        retriever = EnsembleRetriever(
            retrievers=[bm25, dense, raptor],
            name="ensemble_rrf_raptor_refine"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "dense", "raptor", "refine"]

    # RRF + Summary (S11) - BM25 + Dense(notion_summary)
    elif retriever_type == "ensemble_rrf_summary":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense_summary = DenseRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_summary"
        )
        retriever = EnsembleRetriever(
            retrievers=[bm25, dense_summary],
            name="ensemble_rrf_summary"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "dense", "summary", "s11"]

    # RRF + Mixed (S12) - BM25 + Dense(notion_mixed)
    elif retriever_type == "ensemble_rrf_mixed":
        bm25 = BM25Retriever(qdrant_client, use_korean_tokenizer=True)
        embedder = get_cached_embedder()
        dense_mixed = DenseRetriever(
            qdrant_client=qdrant_client,
            embedder=embedder,
            collection_name="notion_mixed"
        )
        retriever = EnsembleRetriever(
            retrievers=[bm25, dense_mixed],
            name="ensemble_rrf_mixed"
        )
        retriever_tags = ["ensemble", "rrf", "bm25", "dense", "mixed", "s12"]

    # QueryRewrite ë¦¬íŠ¸ë¦¬ë²„
    elif retriever_type == "query_rewrite":
        # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
        base_retriever, base_tags = create_retriever(
            base_retriever_type,
            qdrant_client,
            embedding_cache,
            decay_rate=decay_rate
        )
        retriever = QueryRewriteRetriever(
            base_retriever=base_retriever,
            name=f"query_rewrite_{base_retriever.name}"
        )
        retriever_tags = ["query_rewrite", "llm_optimization"] + base_tags

    else:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…: {retriever_type}")

    return retriever, retriever_tags


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description="í†µí•© RAG ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        "--retriever",
        type=str,
        required=False,
        choices=list(AVAILABLE_RETRIEVERS.keys()),
        help="í‰ê°€í•  ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…"
    )
    parser.add_argument(
        "--list-retrievers",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì… ëª©ë¡ ì¶œë ¥"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        default=DEFAULT_DATASET_PATH,
        help="í‰ê°€ ë°ì´í„°ì…‹ ê²½ë¡œ"
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=DEFAULT_TOP_K,
        help="ê²€ìƒ‰í•  ìƒìœ„ kê°œ ë¬¸ì„œ"
    )
    parser.add_argument(
        "--version",
        type=str,
        default="v1",
        help="ë²„ì „ íƒœê·¸"
    )
    parser.add_argument(
        "--no-cache",
        action="store_true",
        help="ì„ë² ë”© ìºì‹œ ë¹„í™œì„±í™”"
    )

    # MultiQuery ê´€ë ¨ ì˜µì…˜
    parser.add_argument(
        "--base-retriever",
        type=str,
        choices=list(AVAILABLE_RETRIEVERS.keys()),
        default="ensemble_rrf",
        help="MultiQueryì˜ ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì… (ê¸°ë³¸ê°’: ensemble_rrf)"
    )
    parser.add_argument(
        "--num-queries",
        type=int,
        default=DEFAULT_NUM_QUERIES,
        help="MultiQueryì—ì„œ ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’: 3)"
    )

    # TimeWeighted ê´€ë ¨ ì˜µì…˜
    parser.add_argument(
        "--decay-rate",
        type=float,
        default=DEFAULT_DECAY_RATE,
        help="TimeWeighted ë¦¬íŠ¸ë¦¬ë²„ì˜ decay rate (ê¸°ë³¸ê°’: 0.01)"
    )

    args = parser.parse_args()

    # ë¦¬íŠ¸ë¦¬ë²„ ëª©ë¡ ì¶œë ¥
    if args.list_retrievers:
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì…:")
        for ret_type, description in AVAILABLE_RETRIEVERS.items():
            print(f"  {ret_type:<30} - {description}")
        return

    # ë¦¬íŠ¸ë¦¬ë²„ íƒ€ì… í•„ìˆ˜ í™•ì¸
    if not args.retriever:
        parser.error("--retriever ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤. --list-retrieversë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ íƒ€ì…ì„ í™•ì¸í•˜ì„¸ìš”.")

    print("=" * 60)
    print(f"ğŸ“Š {AVAILABLE_RETRIEVERS[args.retriever]} í‰ê°€")
    print("=" * 60)

    # Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    langfuse = get_langfuse_client()
    if not langfuse:
        print("âŒ Langfuse í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    qdrant_client = QdrantClient(path=QDRANT_PATH)

    # í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ
    eval_data = load_evaluation_dataset(args.dataset)
    print(f"\nâœ… í‰ê°€ ë°ì´í„°: {len(eval_data)}ê°œ ì§ˆë¬¸")

    # ì„ë² ë”© ìºì‹œ ì´ˆê¸°í™”
    use_cache = not args.no_cache
    embedding_cache = EmbeddingCache() if use_cache else None

    if use_cache:
        print("ğŸ’¾ ì„ë² ë”© ìºì‹œ í™œì„±í™”")

    # ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    print(f"\nğŸ“¦ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì¤‘...")
    retriever, retriever_tags = create_retriever(
        retriever_type=args.retriever,
        qdrant_client=qdrant_client,
        embedding_cache=embedding_cache,
        base_retriever_type=args.base_retriever,
        num_queries=args.num_queries,
        decay_rate=args.decay_rate
    )

    print(f"âœ… ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ: {retriever.name}")
    print(f"   - íƒ€ì…: {args.retriever}")
    print(f"   - íƒœê·¸: {', '.join(retriever_tags)}")

    if args.retriever == "multiquery":
        print(f"   - ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„: {args.base_retriever}")
        print(f"   - ìƒì„±í•  ì¿¼ë¦¬ ìˆ˜: {args.num_queries}")

    if "time_weighted" in retriever_tags:
        print(f"   - Decay rate: {args.decay_rate}")

    # í‰ê°€ ìˆ˜í–‰
    stats = evaluate_retriever(
        retriever,
        eval_data,
        langfuse,
        args.top_k,
        args.version,
        retriever_tags=retriever_tags
    )

    # ì„ë² ë”© ìºì‹œ ì €ì¥
    if use_cache and embedding_cache:
        print("\nğŸ’¾ ì„ë² ë”© ìºì‹œ ì €ì¥ ì¤‘...")
        embedding_cache.save()
        embedding_cache.print_stats()

    # Langfuse flush
    print("\nâ³ Langfuseì— ë°ì´í„° ì „ì†¡ ì¤‘...")
    langfuse.flush()

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“ˆ í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    print(f"ë¦¬íŠ¸ë¦¬ë²„: {retriever.name}")
    print(f"ì´ ì¿¼ë¦¬: {stats['total_queries']}")
    print(f"í‰ê·  ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {stats['avg_contexts']:.2f}")
    print(f"í‰ê·  ì‹œê°„: {stats['avg_time']*1000:.2f}ms")

    print("\n" + "=" * 60)
    print("âœ… í‰ê°€ ì™„ë£Œ!")
    print("=" * 60)
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. ğŸŒ Langfuse ëŒ€ì‹œë³´ë“œ: https://cloud.langfuse.com")
    print(f"   2. ğŸ“Š Traces íƒ­ì—ì„œ ìƒì„±ëœ trace í™•ì¸")
    print(f"   3. ğŸ”§ Settings â†’ Evaluations â†’ RAGAS ë©”íŠ¸ë¦­ ì„¤ì •")
    print(f"   4. âš™ï¸  Evaluations íƒ­ì—ì„œ ìë™ í‰ê°€ ê²°ê³¼ í™•ì¸")

    # ê²°ê³¼ ì €ì¥
    output_file = Path(args.dataset).parent / f"{args.retriever}_evaluation_stats.json"
    save_result = {k: v for k, v in stats.items() if k != "evaluations"}
    save_result["num_evaluations"] = len(stats.get("evaluations", []))
    save_result["config"] = {
        "retriever_type": args.retriever,
        "retriever_name": retriever.name,
        "retriever_tags": retriever_tags,
        "top_k": args.top_k,
        "version": args.version,
    }

    # ì¶”ê°€ ì„¤ì • ì •ë³´
    if args.retriever == "multiquery":
        save_result["config"]["base_retriever"] = args.base_retriever
        save_result["config"]["num_queries"] = args.num_queries

    if "time_weighted" in retriever_tags:
        save_result["config"]["decay_rate"] = args.decay_rate

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(save_result, f, indent=2, ensure_ascii=False, default=str)

    print(f"\nğŸ’¾ í†µê³„ ì €ì¥: {output_file}")


if __name__ == "__main__":
    main()
