#!/usr/bin/env python3
"""í‰ê°€ ë°ì´í„°ì…‹ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import random
from typing import List, Dict, Any, Optional
from utils.file_utils import load_json, save_json
from config.settings import DATA_DIR


def load_notion_data() -> List[Dict[str, Any]]:
    """Notion ë°ì´í„° ë¡œë“œ"""
    data_file = DATA_DIR / "notion_data.json"
    if not data_file.exists():
        raise FileNotFoundError(
            f"Notion ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {data_file}\n"
            "ë¨¼ì € 'python scripts/build_vectordb.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )
    return load_json(str(data_file))


def extract_text_from_page(page: Dict[str, Any], max_length: int = 500) -> str:
    """í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    # content í•„ë“œê°€ ë¬¸ìì—´ë¡œ ì œê³µë˜ëŠ” ê²½ìš°
    content = page.get("content", "")

    if isinstance(content, str):
        # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°
        import re
        content = re.sub(r'\[Image:.*?\]', '', content)

        # ê¸¸ì´ ì œí•œ
        if len(content) > max_length:
            content = content[:max_length] + "..."

        return content.strip()

    # ê¸°ì¡´ blocks í˜•ì‹ ì§€ì› (í˜¸í™˜ì„±)
    texts = []
    for block in page.get("blocks", []):
        block_type = block.get("type")

        if block_type in ["paragraph", "heading_1", "heading_2", "heading_3"]:
            rich_texts = block.get(block_type, {}).get("rich_text", [])
            for rt in rich_texts:
                text = rt.get("plain_text", "").strip()
                if text:
                    texts.append(text)

        elif block_type == "bulleted_list_item":
            rich_texts = block.get("bulleted_list_item", {}).get("rich_text", [])
            for rt in rich_texts:
                text = rt.get("plain_text", "").strip()
                if text:
                    texts.append(f"â€¢ {text}")

    full_text = " ".join(texts)

    # ê¸¸ì´ ì œí•œ
    if len(full_text) > max_length:
        full_text = full_text[:max_length] + "..."

    return full_text


def generate_manual_template(
    pages: List[Dict[str, Any]],
    num_samples: int = 10,
    output_file: str = "data/evaluation/manual_qa_template.json"
) -> List[Dict[str, Any]]:
    """
    ìˆ˜ë™ ì‘ì„±ìš© QA í…œí”Œë¦¿ ìƒì„±

    Args:
        pages: Notion í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        num_samples: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
        output_file: ì €ì¥ ê²½ë¡œ

    Returns:
        í…œí”Œë¦¿ ë°ì´í„°
    """
    print(f"\nğŸ“ ìˆ˜ë™ ì‘ì„±ìš© í…œí”Œë¦¿ ìƒì„± ì¤‘... (ìƒ˜í”Œ ìˆ˜: {num_samples})")

    # ëœë¤ìœ¼ë¡œ í˜ì´ì§€ ì„ íƒ
    selected_pages = random.sample(pages, min(num_samples, len(pages)))

    template_data = []

    for i, page in enumerate(selected_pages, 1):
        page_title = page.get("title", "Untitled")
        page_id = page.get("page_id", "")
        content_preview = extract_text_from_page(page, max_length=300)

        template_data.append({
            "id": f"qa_{i}",
            "question": f"[TODO: {page_title}ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”]",
            "ground_truth": "[TODO: ì •ë‹µì„ ì‘ì„±í•˜ì„¸ìš”]",
            "context_page_id": page_id,
            "context_page_title": page_title,
            "content_preview": content_preview,
            "metadata": {
                "category": "[TODO: ì¹´í…Œê³ ë¦¬]",
                "difficulty": "medium",
                "source": "manual"
            }
        })

    # ì €ì¥
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    save_json(template_data, str(output_path))

    print(f"âœ… í…œí”Œë¦¿ ì €ì¥: {output_path}")
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. {output_path} íŒŒì¼ì„ ì—´ê¸°")
    print(f"   2. [TODO] ë¶€ë¶„ì„ ì‹¤ì œ ì§ˆë¬¸/ë‹µë³€ìœ¼ë¡œ ìˆ˜ì •")
    print(f"   3. content_previewë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±")

    return template_data


def generate_simple_qa_from_headings(
    pages: List[Dict[str, Any]],
    num_samples: int = 20,
    output_file: str = "data/evaluation/auto_qa_from_headings.json"
) -> List[Dict[str, Any]]:
    """
    ì œëª©/í—¤ë”© ê¸°ë°˜ ê°„ë‹¨í•œ QA ìƒì„±

    Args:
        pages: Notion í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        num_samples: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
        output_file: ì €ì¥ ê²½ë¡œ

    Returns:
        QA ë°ì´í„°
    """
    print(f"\nğŸ¤– ì œëª© ê¸°ë°˜ ìë™ QA ìƒì„± ì¤‘... (ìƒ˜í”Œ ìˆ˜: {num_samples})")

    qa_data = []

    for page in pages:
        page_title = page.get("title", "").strip()
        page_id = page.get("page_id", "")

        if not page_title:
            continue

        # í˜ì´ì§€ì—ì„œ í—¤ë”©ê³¼ ë‚´ìš© ì¶”ì¶œ
        headings_with_content = []
        current_heading = None
        current_content = []

        for block in page.get("blocks", []):
            block_type = block.get("type")

            if block_type in ["heading_1", "heading_2", "heading_3"]:
                # ì´ì „ í—¤ë”© ì €ì¥
                if current_heading and current_content:
                    headings_with_content.append({
                        "heading": current_heading,
                        "content": " ".join(current_content)
                    })

                # ìƒˆ í—¤ë”© ì‹œì‘
                rich_texts = block.get(block_type, {}).get("rich_text", [])
                current_heading = " ".join([rt.get("plain_text", "") for rt in rich_texts]).strip()
                current_content = []

            elif block_type == "paragraph":
                rich_texts = block.get("paragraph", {}).get("rich_text", [])
                text = " ".join([rt.get("plain_text", "") for rt in rich_texts]).strip()
                if text:
                    current_content.append(text)

        # ë§ˆì§€ë§‰ í—¤ë”© ì €ì¥
        if current_heading and current_content:
            headings_with_content.append({
                "heading": current_heading,
                "content": " ".join(current_content)
            })

        # QA ìƒì„±
        # 1. í˜ì´ì§€ ì œëª© ê¸°ë°˜ ì§ˆë¬¸
        qa_data.append({
            "question": f"{page_title}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ground_truth": extract_text_from_page(page, max_length=500),
            "context_page_id": page_id,
            "metadata": {
                "category": "page_summary",
                "difficulty": "easy",
                "source": "auto_title"
            }
        })

        # 2. ê° í—¤ë”© ê¸°ë°˜ ì§ˆë¬¸
        for heading_data in headings_with_content[:3]:  # ìµœëŒ€ 3ê°œ
            heading = heading_data["heading"]
            content = heading_data["content"]

            if len(content) < 50:  # ë„ˆë¬´ ì§§ì€ ë‚´ìš©ì€ ìŠ¤í‚µ
                continue

            qa_data.append({
                "question": f"{page_title}ì˜ '{heading}' ì„¹ì…˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "ground_truth": content[:500],
                "context_page_id": page_id,
                "metadata": {
                    "category": "section_explanation",
                    "difficulty": "medium",
                    "source": "auto_heading"
                }
            })

        if len(qa_data) >= num_samples:
            break

    # ìƒ˜í”Œ ìˆ˜ë§Œí¼ ìë¥´ê¸°
    qa_data = qa_data[:num_samples]

    # ì €ì¥
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    save_json(qa_data, str(output_path))

    print(f"âœ… ìë™ QA ìƒì„± ì™„ë£Œ: {len(qa_data)}ê°œ")
    print(f"âœ… ì €ì¥ ìœ„ì¹˜: {output_path}")

    return qa_data


def generate_qa_with_llm(
    pages: List[Dict[str, Any]],
    num_samples: int = 10,
    llm_provider: str = "openai",
    output_file: str = "data/evaluation/llm_generated_qa.json"
) -> List[Dict[str, Any]]:
    """
    LLMì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ QA ìƒì„±

    Args:
        pages: Notion í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        num_samples: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜
        llm_provider: LLM ì œê³µì (openai, azure, openrouter)
        output_file: ì €ì¥ ê²½ë¡œ

    Returns:
        QA ë°ì´í„°
    """
    print(f"\nğŸ¤– LLM ê¸°ë°˜ QA ìƒì„± ì¤‘... (ìƒ˜í”Œ ìˆ˜: {num_samples})")

    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if llm_provider == "openai":
            from openai import OpenAI
            import os

            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            client = OpenAI(api_key=api_key)
            model = "gpt-4o-mini"

        elif llm_provider == "azure":
            from openai import OpenAI
            from config.settings import AZURE_AI_CREDENTIAL, AZURE_AI_ENDPOINT

            if not AZURE_AI_CREDENTIAL:
                raise ValueError("AZURE_AI_CREDENTIALì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            client = OpenAI(
                api_key=AZURE_AI_CREDENTIAL,
                base_url=AZURE_AI_ENDPOINT
            )
            # Azure AIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
            model = "gpt-5.1"

        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {llm_provider}")

        qa_data = []
        selected_pages = random.sample(pages, min(num_samples, len(pages)))

        for page in selected_pages:
            page_title = page.get("title", "Untitled")
            page_id = page.get("page_id", "")
            content = extract_text_from_page(page, max_length=1000)

            if len(content) < 100:
                print(f"  â­ï¸  {page_title}: ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ ({len(content)}ì), ìŠ¤í‚µ")
                continue

            # LLM í”„ë¡¬í”„íŠ¸
            prompt = f"""ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ì½ê³  í‰ê°€ìš© ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ì œëª©: {page_title}
ë¬¸ì„œ ë‚´ìš©:
{content}

ìš”êµ¬ì‚¬í•­:
1. ë¬¸ì„œ ë‚´ìš©ì„ ì˜ í‰ê°€í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì§ˆë¬¸ 1ê°œ ìƒì„±
2. ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ ì‘ì„±
3. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ

ì‘ë‹µ í˜•ì‹:
{{
  "question": "ì§ˆë¬¸ ë‚´ìš©",
  "ground_truth": "ë‹µë³€ ë‚´ìš©"
}}
"""

            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ RAG ì‹œìŠ¤í…œ í‰ê°€ë¥¼ ìœ„í•œ ê³ í’ˆì§ˆ QA ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    response_format={"type": "json_object"}
                )

                result = json.loads(response.choices[0].message.content)

                qa_data.append({
                    "question": result.get("question", ""),
                    "ground_truth": result.get("ground_truth", ""),
                    "context_page_id": page_id,
                    "metadata": {
                        "category": "llm_generated",
                        "difficulty": "medium",
                        "source": f"llm_{llm_provider}",
                        "page_title": page_title
                    }
                })

                print(f"  âœ… {page_title}: QA ìƒì„± ì™„ë£Œ")

            except Exception as e:
                print(f"  âŒ {page_title}: QA ìƒì„± ì‹¤íŒ¨ - {e}")
                continue

        # ì €ì¥
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        save_json(qa_data, str(output_path))

        print(f"\nâœ… LLM ê¸°ë°˜ QA ìƒì„± ì™„ë£Œ: {len(qa_data)}ê°œ")
        print(f"âœ… ì €ì¥ ìœ„ì¹˜: {output_path}")

        return qa_data

    except Exception as e:
        print(f"\nâŒ LLM ê¸°ë°˜ QA ìƒì„± ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ Tip: API í‚¤ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ --method auto ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        return []


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±")
    parser.add_argument(
        "--method",
        type=str,
        choices=["manual", "auto", "llm"],
        default="auto",
        help="ìƒì„± ë°©ë²•: manual(ìˆ˜ë™ í…œí”Œë¦¿), auto(ìë™), llm(LLM ì‚¬ìš©)"
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=20,
        help="ìƒì„±í•  ìƒ˜í”Œ ìˆ˜"
    )
    parser.add_argument(
        "--llm-provider",
        type=str,
        choices=["openai", "azure"],
        default="azure",
        help="LLM ì œê³µì (llm ë°©ë²• ì‚¬ìš© ì‹œ)"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ"
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ“Š í‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
    print("=" * 60)

    # Notion ë°ì´í„° ë¡œë“œ
    pages = load_notion_data()
    print(f"\nâœ… Notion ë°ì´í„° ë¡œë“œ: {len(pages)}ê°œ í˜ì´ì§€")

    # ìƒì„± ë°©ë²•ì— ë”°ë¼ ì‹¤í–‰
    if args.method == "manual":
        output = args.output or "data/evaluation/manual_qa_template.json"
        generate_manual_template(pages, args.num_samples, output)

    elif args.method == "auto":
        output = args.output or "data/evaluation/auto_qa_from_headings.json"
        generate_simple_qa_from_headings(pages, args.num_samples, output)

    elif args.method == "llm":
        output = args.output or f"data/evaluation/llm_generated_qa_{args.llm_provider}.json"
        generate_qa_with_llm(pages, args.num_samples, args.llm_provider, output)

    print("\n" + "=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
