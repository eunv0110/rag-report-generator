#!/usr/bin/env python3
"""ë¦¬íŠ¸ë¦¬ë²„ í‰ê°€ ê²°ê³¼ ë¹„êµ (Langfuse íƒœê·¸ ê¸°ë°˜)

Langfuseì— ì €ì¥ëœ í‰ê°€ ê²°ê³¼ë¥¼ íƒœê·¸ë¡œ í•„í„°ë§í•˜ì—¬
ì—¬ëŸ¬ ë¦¬íŠ¸ë¦¬ë²„ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from typing import List, Dict, Any, Optional
from collections import defaultdict
import json
from utils.langfuse_utils import get_langfuse_client


def fetch_traces_by_tag(langfuse, tag: str, limit: int = 1000) -> List[Dict[str, Any]]:
    """
    íŠ¹ì • íƒœê·¸ë¡œ traces ê°€ì ¸ì˜¤ê¸°

    Args:
        langfuse: Langfuse í´ë¼ì´ì–¸íŠ¸
        tag: í•„í„°ë§í•  íƒœê·¸
        limit: ìµœëŒ€ ê°€ì ¸ì˜¬ trace ìˆ˜

    Returns:
        trace ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ” íƒœê·¸ '{tag}'ë¡œ traces ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

    try:
        traces = langfuse.fetch_traces(
            tags=[tag],
            limit=limit
        )

        trace_list = list(traces.data)
        print(f"   âœ… {len(trace_list)}ê°œ traces ê°€ì ¸ì˜´")
        return trace_list

    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")
        return []


def get_trace_scores(langfuse, trace_id: str) -> Dict[str, float]:
    """
    íŠ¹ì • traceì˜ ëª¨ë“  scores ê°€ì ¸ì˜¤ê¸°

    Args:
        langfuse: Langfuse í´ë¼ì´ì–¸íŠ¸
        trace_id: trace ID

    Returns:
        {score_name: score_value} ë”•ì…”ë„ˆë¦¬
    """
    try:
        trace = langfuse.fetch_trace(trace_id)
        scores = {}

        if hasattr(trace, 'scores') and trace.scores:
            for score in trace.scores:
                scores[score.name] = score.value

        return scores

    except Exception as e:
        print(f"   âš ï¸  Trace {trace_id} scores ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}


def analyze_retriever_performance(
    langfuse,
    version_tag: str = "3",
    retriever_names: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    ê° ë¦¬íŠ¸ë¦¬ë²„ì˜ ì„±ëŠ¥ ë¶„ì„

    Args:
        langfuse: Langfuse í´ë¼ì´ì–¸íŠ¸
        version_tag: ë²„ì „ íƒœê·¸ (ì˜ˆ: "v2")
        retriever_names: ë¶„ì„í•  ë¦¬íŠ¸ë¦¬ë²„ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ íƒì§€)

    Returns:
        ë¦¬íŠ¸ë¦¬ë²„ë³„ ì„±ëŠ¥ í†µê³„
    """
    if retriever_names is None:
        retriever_names = ["BM25_Basic", "Dense_Vector", "rrf_ensemble"]

    results = {}

    for retriever_name in retriever_names:
        tag = f"{retriever_name}_{version_tag}"
        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š {retriever_name} ë¶„ì„ ì¤‘...")
        print(f"{'=' * 60}")

        # 1. í•´ë‹¹ ë¦¬íŠ¸ë¦¬ë²„ì˜ ëª¨ë“  traces ê°€ì ¸ì˜¤ê¸°
        traces = fetch_traces_by_tag(langfuse, tag)

        if not traces:
            print(f"   âš ï¸  '{tag}' íƒœê·¸ë¡œ tracesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        # 2. ê° traceì˜ ë©”íƒ€ë°ì´í„° ë° scores ìˆ˜ì§‘
        trace_data = []
        scores_summary = defaultdict(list)

        for trace in traces:
            trace_info = {
                "trace_id": trace.id,
                "name": trace.name,
                "timestamp": trace.timestamp,
            }

            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            if hasattr(trace, 'metadata') and trace.metadata:
                trace_info["metadata"] = trace.metadata
                trace_info["total_time_ms"] = trace.metadata.get("total_time_ms", 0)
                trace_info["num_contexts"] = trace.metadata.get("num_retrieved_contexts", 0)

            # Scores ê°€ì ¸ì˜¤ê¸°
            scores = get_trace_scores(langfuse, trace.id)
            trace_info["scores"] = scores

            # í†µê³„ë¥¼ ìœ„í•œ scores ìˆ˜ì§‘
            for score_name, score_value in scores.items():
                scores_summary[score_name].append(score_value)

            trace_data.append(trace_info)

        # 3. í†µê³„ ê³„ì‚°
        stats = {
            "retriever": retriever_name,
            "version": version_tag,
            "total_traces": len(traces),
            "avg_time_ms": sum(t.get("total_time_ms", 0) for t in trace_data) / len(trace_data) if trace_data else 0,
            "avg_contexts": sum(t.get("num_contexts", 0) for t in trace_data) / len(trace_data) if trace_data else 0,
            "scores": {}
        }

        # Scores í‰ê·  ê³„ì‚°
        for score_name, values in scores_summary.items():
            if values:
                stats["scores"][score_name] = {
                    "avg": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values),
                    "count": len(values)
                }

        results[retriever_name] = {
            "stats": stats,
            "traces": trace_data
        }

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“ˆ {retriever_name} í†µê³„:")
        print(f"   Total traces: {stats['total_traces']}")
        print(f"   Avg time: {stats['avg_time_ms']:.2f} ms")
        print(f"   Avg contexts: {stats['avg_contexts']:.2f}")

        if stats["scores"]:
            print(f"\n   Scores:")
            for score_name, score_stats in stats["scores"].items():
                print(f"      {score_name}:")
                print(f"         í‰ê· : {score_stats['avg']:.4f}")
                print(f"         ë²”ìœ„: {score_stats['min']:.4f} ~ {score_stats['max']:.4f}")
                print(f"         ê°œìˆ˜: {score_stats['count']}")

    return results


def compare_retrievers(
    langfuse,
    version_tag: str = "v3",
    retriever_names: Optional[List[str]] = None
):
    """ë¦¬íŠ¸ë¦¬ë²„ ì„±ëŠ¥ ë¹„êµ ë° ì¶œë ¥"""
    results = analyze_retriever_performance(langfuse, version_tag, retriever_names)

    if not results:
        print("\nâŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¹„êµ í…Œì´ë¸” ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ† ë¦¬íŠ¸ë¦¬ë²„ ì„±ëŠ¥ ë¹„êµ")
    print("=" * 80)

    # í—¤ë”
    print(f"\n{'Retriever':<20} {'Traces':<10} {'Avg Time (ms)':<15} {'Avg Contexts':<15}")
    print("-" * 70)

    # ê° ë¦¬íŠ¸ë¦¬ë²„ í†µê³„
    for retriever_name, data in results.items():
        stats = data["stats"]
        print(
            f"{retriever_name:<20} "
            f"{stats['total_traces']:<10} "
            f"{stats['avg_time_ms']:<15.2f} "
            f"{stats['avg_contexts']:<15.2f}"
        )

    # Scores ë¹„êµ (ìˆëŠ” ê²½ìš°)
    all_score_names = set()
    for data in results.values():
        all_score_names.update(data["stats"]["scores"].keys())

    if all_score_names:
        print("\n" + "=" * 80)
        print("ğŸ“Š Scores ë¹„êµ")
        print("=" * 80)

        for score_name in sorted(all_score_names):
            print(f"\n{score_name}:")
            print(f"{'Retriever':<20} {'í‰ê· ':<15} {'ìµœì†Œ':<15} {'ìµœëŒ€':<15}")
            print("-" * 70)

            for retriever_name, data in results.items():
                if score_name in data["stats"]["scores"]:
                    score_stats = data["stats"]["scores"][score_name]
                    print(
                        f"{retriever_name:<20} "
                        f"{score_stats['avg']:<15.4f} "
                        f"{score_stats['min']:<15.4f} "
                        f"{score_stats['max']:<15.4f}"
                    )

    # ê²°ê³¼ ì €ì¥
    output_file = Path(__file__).parent.parent / "data" / "evaluation" / f"retriever_comparison_{version_tag}.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    # traces ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  statsë§Œ ì €ì¥
    save_data = {
        retriever: data["stats"]
        for retriever, data in results.items()
    }

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Langfuseì—ì„œ íƒœê·¸ë¡œ ë¦¬íŠ¸ë¦¬ë²„ ì„±ëŠ¥ ë¹„êµ",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "--version",
        type=str,
        default="v2",
        help="ë¹„êµí•  ë²„ì „ íƒœê·¸ (ê¸°ë³¸ê°’: v2)"
    )
    parser.add_argument(
        "--retrievers",
        type=str,
        nargs="+",
        default=None,
        help="ë¹„êµí•  ë¦¬íŠ¸ë¦¬ë²„ ì´ë¦„ (ê¸°ë³¸ê°’: BM25_Basic Dense_Vector rrf_ensemble)"
    )

    args = parser.parse_args()

    # Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("ğŸ”§ Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    langfuse = get_langfuse_client()

    if not langfuse:
        print("âŒ Langfuse í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì—ì„œ LANGFUSE_PUBLIC_KEYì™€ LANGFUSE_SECRET_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print("âœ… Langfuse ì—°ê²° ì„±ê³µ\n")

    # ë¦¬íŠ¸ë¦¬ë²„ ë¹„êµ
    compare_retrievers(
        langfuse=langfuse,
        version_tag=args.version,
        retriever_names=args.retrievers
    )


if __name__ == "__main__":
    main()
