import os
import re
import httpx
from typing import List, Dict, Optional
from pathlib import Path
from notion_client import Client
from config.settings import IMAGE_DIR, NOTION_VERSION


class NotionDataSourceCollector:
    """Notion Data Sourceì—ì„œë§Œ ë°ì´í„° ìˆ˜ì§‘"""
    
    def __init__(self, token: str, data_source_id: str):
        if not data_source_id:
            raise ValueError("DATA_SOURCE_IDê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        self.client = Client(auth=token, notion_version=os.environ.get("NOTION_VERSION", "2025-09-03"))
        self.data_source_id = data_source_id
        
        # âœ… Path ê°ì²´ë¡œ ë³€ê²½
        self.image_dir = Path(IMAGE_DIR)
        self.image_dir.mkdir(parents=True, exist_ok=True)
    
    def get_all_blocks(self, block_id: str) -> List[Dict]:
        """ëª¨ë“  ë¸”ë¡ì„ ì¬ê·€ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ í¬í•¨)"""
        all_blocks = []
        cursor = None
        
        while True:
            response = self.client.blocks.children.list(
                block_id=block_id,
                start_cursor=cursor
            )
            all_blocks.extend(response["results"])
            
            if not response.get("has_more"):
                break
            cursor = response["next_cursor"]
        
        # í•˜ìœ„ ë¸”ë¡ ì¬ê·€ íƒìƒ‰
        for block in all_blocks:
            if block.get("has_children"):
                block["children"] = self.get_all_blocks(block["id"])
        
        return all_blocks
    
    def extract_rich_text(self, rich_text_list: List) -> str:
        """rich_text ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not rich_text_list:
            return ""
        return "".join([t.get("plain_text", "") for t in rich_text_list])
    
    def download_image(self, url: str, page_id: str, block_id: str) -> Optional[str]:
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í›„ ìƒëŒ€ ê²½ë¡œ ë°˜í™˜"""
        try:
            response = httpx.get(url, timeout=30)
            if response.status_code == 200:
                ext = "png"
                if "." in url.split("?")[0]:
                    ext = url.split("?")[0].split(".")[-1][:4]
                
                # âœ… ì ˆëŒ€ ê²½ë¡œë¡œ ì €ì¥
                filename = self.image_dir / f"{page_id}_{block_id}.{ext}"
                with open(filename, "wb") as f:
                    f.write(response.content)
                
                # âœ… ìƒëŒ€ ê²½ë¡œë§Œ ë°˜í™˜ (notion_images/xxx.png)
                return f"notion_images/{page_id}_{block_id}.{ext}"
        except Exception as e:
            print(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    def extract_block_content(self, block: Dict, page_id: str, depth: int = 0) -> str:
        """ë¸”ë¡ì—ì„œ ëª¨ë“  ë‚´ìš© ì¶”ì¶œ"""
        block_type = block["type"]
        block_id = block["id"]
        indent = "  " * depth
        result = ""
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ë“¤
        text_types = [
            "paragraph", "heading_1", "heading_2", "heading_3",
            "bulleted_list_item", "numbered_list_item", 
            "quote", "toggle", "to_do", "callout"
        ]
        
        if block_type in text_types:
            text = self.extract_rich_text(block[block_type].get("rich_text", []))
            
            if block_type == "heading_1":
                result = f"{indent}# {text}"
            elif block_type == "heading_2":
                result = f"{indent}## {text}"
            elif block_type == "heading_3":
                result = f"{indent}### {text}"
            elif block_type == "bulleted_list_item":
                result = f"{indent}â€¢ {text}"
            elif block_type == "numbered_list_item":
                result = f"{indent}1. {text}"
            elif block_type == "quote":
                result = f"{indent}> {text}"
            elif block_type == "to_do":
                checked = "âœ…" if block["to_do"].get("checked") else "â¬œ"
                result = f"{indent}{checked} {text}"
            elif block_type == "callout":
                emoji = block["callout"].get("icon", {}).get("emoji", "ğŸ’¡")
                result = f"{indent}{emoji} {text}"
            else:
                result = f"{indent}{text}"
        
        # ì½”ë“œ ë¸”ë¡
        elif block_type == "code":
            code = self.extract_rich_text(block["code"].get("rich_text", []))
            lang = block["code"].get("language", "")
            caption = self.extract_rich_text(block["code"].get("caption", []))
            result = f"{indent}```{lang}\n{code}\n{indent}```"
            if caption:
                result += f"\n{indent}Caption: {caption}"
        
        # ì´ë¯¸ì§€
        elif block_type == "image":
            image_data = block["image"]
            url = None
            if image_data["type"] == "file":
                url = image_data["file"]["url"]
            elif image_data["type"] == "external":
                url = image_data["external"]["url"]
            
            if url:
                local_path = self.download_image(url, page_id, block_id)
                caption = self.extract_rich_text(image_data.get("caption", []))
                result = f"{indent}[Image: {local_path or url}]"
                if caption:
                    result += f" - {caption}"
        
        # ë¹„ë””ì˜¤
        elif block_type == "video":
            video_data = block["video"]
            url = video_data.get("file", {}).get("url") or video_data.get("external", {}).get("url", "unknown")
            result = f"{indent}[Video: {url}]"
        
        # íŒŒì¼
        elif block_type == "file":
            file_data = block["file"]
            url = file_data.get("file", {}).get("url") or file_data.get("external", {}).get("url", "unknown")
            name = file_data.get("name", "file")
            result = f"{indent}[File: {name} - {url}]"
        
        # ë¶ë§ˆí¬
        elif block_type == "bookmark":
            url = block["bookmark"].get("url", "")
            caption = self.extract_rich_text(block["bookmark"].get("caption", []))
            result = f"{indent}[Bookmark: {url}]"
            if caption:
                result += f" - {caption}"
        
        # ì„ë² ë“œ
        elif block_type == "embed":
            url = block["embed"].get("url", "")
            result = f"{indent}[Embed: {url}]"
        
        # í…Œì´ë¸” í–‰
        elif block_type == "table_row":
            cells = block["table_row"].get("cells", [])
            row_data = [self.extract_rich_text(cell) for cell in cells]
            result = f"{indent}| " + " | ".join(row_data) + " |"
        
        # êµ¬ë¶„ì„ 
        elif block_type == "divider":
            result = f"{indent}---"
        
        # ë§í¬ í”„ë¦¬ë·°
        elif block_type == "link_preview":
            url = block["link_preview"].get("url", "")
            result = f"{indent}[Link: {url}]"
        
        # PDF
        elif block_type == "pdf":
            pdf_data = block["pdf"]
            url = pdf_data.get("file", {}).get("url") or pdf_data.get("external", {}).get("url", "unknown")
            result = f"{indent}[PDF: {url}]"
        
        # ìˆ˜ì‹
        elif block_type == "equation":
            expr = block["equation"].get("expression", "")
            result = f"{indent}[Equation: {expr}]"
        
        # ìì‹ í˜ì´ì§€
        elif block_type == "child_page":
            title = block["child_page"].get("title", "")
            result = f"{indent}ğŸ“„ [{title}]"
        
        # ìì‹ ë°ì´í„°ë² ì´ìŠ¤
        elif block_type == "child_database":
            title = block["child_database"].get("title", "")
            result = f"{indent}ğŸ—ƒï¸ [{title}]"
        
        # ê¸°íƒ€ (table, column_list ë“±ì€ ë¬´ì‹œ)
        elif block_type not in ["table", "column_list", "column", "synced_block"]:
            result = f"{indent}[{block_type}]"
        
        # í•˜ìœ„ ë¸”ë¡ ì²˜ë¦¬
        if "children" in block:
            for child in block["children"]:
                child_content = self.extract_block_content(child, page_id, depth + 1)
                if child_content:
                    result += "\n" + child_content
        
        return result
    
    def extract_page_properties(self, page: Dict) -> Dict:
        """í˜ì´ì§€ ì†ì„±(ë©”íƒ€ë°ì´í„°) ì¶”ì¶œ"""
        props = page.get("properties", {})
        extracted = {}
        
        for name, prop in props.items():
            prop_type = prop["type"]
            try:
                if prop_type == "title":
                    extracted[name] = self.extract_rich_text(prop["title"])
                elif prop_type == "rich_text":
                    extracted[name] = self.extract_rich_text(prop["rich_text"])
                elif prop_type == "number":
                    extracted[name] = prop["number"]
                elif prop_type == "select":
                    extracted[name] = prop["select"]["name"] if prop["select"] else None
                elif prop_type == "multi_select":
                    extracted[name] = [s["name"] for s in prop["multi_select"]]
                elif prop_type == "date":
                    if prop["date"]:
                        extracted[name] = {"start": prop["date"].get("start"), "end": prop["date"].get("end")}
                elif prop_type == "checkbox":
                    extracted[name] = prop["checkbox"]
                elif prop_type == "url":
                    extracted[name] = prop["url"]
                elif prop_type == "email":
                    extracted[name] = prop["email"]
                elif prop_type == "phone_number":
                    extracted[name] = prop["phone_number"]
                elif prop_type == "created_time":
                    extracted[name] = prop["created_time"]
                elif prop_type == "last_edited_time":
                    extracted[name] = prop["last_edited_time"]
                elif prop_type == "created_by":
                    extracted[name] = prop["created_by"].get("name", prop["created_by"].get("id"))
                elif prop_type == "last_edited_by":
                    extracted[name] = prop["last_edited_by"].get("name", prop["last_edited_by"].get("id"))
                elif prop_type == "files":
                    extracted[name] = []
                    for f in prop["files"]:
                        if f["type"] == "file":
                            extracted[name].append(f["file"]["url"])
                        elif f["type"] == "external":
                            extracted[name].append(f["external"]["url"])
                elif prop_type == "relation":
                    extracted[name] = [r["id"] for r in prop["relation"]]
                elif prop_type == "formula":
                    formula = prop["formula"]
                    extracted[name] = formula.get(formula["type"])
                elif prop_type == "rollup":
                    rollup = prop["rollup"]
                    extracted[name] = rollup.get(rollup["type"])
                elif prop_type == "status":
                    extracted[name] = prop["status"]["name"] if prop["status"] else None
                else:
                    extracted[name] = f"[{prop_type}]"
            except Exception:
                extracted[name] = None
        
        return extracted
    
    def get_page_title(self, properties: Dict) -> str:
        """ì†ì„±ì—ì„œ ì œëª© ì¶”ì¶œ"""
        for name, value in properties.items():
            if isinstance(value, str) and value and name.lower() in ["title", "name", "ì´ë¦„", "ì œëª©"]:
                return value
        for name, value in properties.items():
            if isinstance(value, str) and value:
                return value
        return "Untitled"
    
    def get_all_pages_from_datasource(self) -> List[Dict]:
        """Data Source APIë¡œ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ í¬í•¨)"""
        all_pages = []
        cursor = None
        
        while True:
            response = self.client.data_sources.query(
                data_source_id=self.data_source_id,
                start_cursor=cursor,
                page_size=100
            )
            all_pages.extend(response["results"])
            print(f"  ğŸ“„ {len(all_pages)}ê°œ í˜ì´ì§€ ë¡œë“œë¨...")
            
            if not response.get("has_more"):
                break
            cursor = response["next_cursor"]
        
        return all_pages
    
    def collect_all(self, limit: int = None) -> List[Dict]:
        """Data Sourceì˜ ëª¨ë“  Notion ë°ì´í„° ìˆ˜ì§‘"""
        print("ğŸš€ Notion ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"ğŸ“Š Data Source ID: {self.data_source_id}\n")
        
        pages = self.get_all_pages_from_datasource()
        print(f"\nâœ… ì´ {len(pages)}ê°œ í˜ì´ì§€ ë°œê²¬\n")

        if limit:
            pages = pages[:limit]   # âœ… ì—¬ê¸°ì„œ ì œí•œ     

        all_data = []
        for idx, page in enumerate(pages):
            page_id = page["id"]
            properties = self.extract_page_properties(page)
            title = self.get_page_title(properties)
            
            print(f"[{idx+1}/{len(pages)}] ğŸ“„ {title}")
            
            try:
                blocks = self.get_all_blocks(page_id)
                content_lines = [self.extract_block_content(b, page_id) for b in blocks]
                full_content = "\n".join(filter(None, content_lines))
                
                all_data.append({
                    "page_id": page_id,
                    "title": title,
                    "created_time": page.get("created_time", ""),
                    "last_edited_time": page.get("last_edited_time", ""),
                    "properties": properties,
                    "content": full_content
                })
                print(f"  â†’ {len(blocks)}ê°œ ë¸”ë¡, {len(full_content)}ì")
            except Exception as e:
                print(f"  âš ï¸ ì‹¤íŒ¨: {e}")
                all_data.append({
                    "page_id": page_id, 
                    "title": title, 
                    "content": "",
                    "created_time": page.get("created_time", ""),
                    "last_edited_time": page.get("last_edited_time", ""),
                    "properties": properties
                })
        
        print(f"\nğŸ‰ ì™„ë£Œ! ì´ {len(all_data)}ê°œ í˜ì´ì§€ ìˆ˜ì§‘")
        return all_data