#!/usr/bin/env python3
"""S11: Summary-Level Vector DB êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ (ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰)

Mixed ì»¬ë ‰ì…˜ì—ì„œ ìš”ì•½ë³¸ì„ ë³µì‚¬í•˜ì—¬ Summary ì „ìš© ì»¬ë ‰ì…˜ ìƒì„±
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from config.settings import *
from utils.langfuse_utils import get_langfuse_client, trace_operation
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue
import uuid


def init_summary_collection(
    client: QdrantClient,
    collection_name: str,
    dimension: int,
    recreate: bool = False
):
    """
    Summary Vector DBìš© Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™”

    Args:
        client: Qdrant í´ë¼ì´ì–¸íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        dimension: ë²¡í„° ì°¨ì›
        recreate: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„± ì—¬ë¶€
    """
    if recreate:
        try:
            client.delete_collection(collection_name)
            print(f"  âœ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {collection_name}")
        except:
            pass

    # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    collections = [col.name for col in client.get_collections().collections]

    if collection_name not in collections:
        client.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(
                size=dimension,
                distance=Distance.COSINE
            )
        )
        print(f"  âœ“ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
    else:
        print(f"  âœ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚¬ìš©: {collection_name}")


def main(
    force_recreate: bool = False,
    limit: int = None,
    collection_name: str = "notion_summary",
    source_collection: str = "notion_mixed",
    summary_length: int = 200
):
    """
    S11: Summary-Level Vector DB êµ¬ì¶• ë©”ì¸ í•¨ìˆ˜

    Mixed ì»¬ë ‰ì…˜ì—ì„œ ìš”ì•½ë³¸ì„ ê°€ì ¸ì™€ì„œ Summary ì „ìš© ì»¬ë ‰ì…˜ ìƒì„±

    Args:
        force_recreate: Trueë©´ ì „ì²´ ì¬ìƒì„±
        limit: ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
        collection_name: ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„
        source_collection: ìš”ì•½ë³¸ì„ ê°€ì ¸ì˜¬ Mixed ì»¬ë ‰ì…˜ ì´ë¦„
        summary_length: ìš”ì•½ ìµœëŒ€ ê¸¸ì´ (ì) - Mixedì—ì„œ ê°€ì ¸ì˜¤ë¯€ë¡œ ì‚¬ìš© ì•ˆ í•¨
    """
    print("=" * 60)
    print("ğŸ“ S11: Summary-Level Vector DB êµ¬ì¶• ì‹œì‘")
    print("   (ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰ - ì†ë„ ê°œì„ )")
    print(f"   âœ¨ Mixed ì»¬ë ‰ì…˜ì˜ ìš”ì•½ë³¸ ì¬ì‚¬ìš©!")
    if limit:
        print(f"ğŸ“Š ì œí•œ: {limit}ê°œ í˜ì´ì§€ë§Œ ì²˜ë¦¬")
    print(f"ğŸ“¦ íƒ€ê²Ÿ ì»¬ë ‰ì…˜: {collection_name}")
    print(f"ğŸ“¥ ì†ŒìŠ¤ ì»¬ë ‰ì…˜: {source_collection}")
    print("=" * 60)

    # Langfuse ì´ˆê¸°í™”
    get_langfuse_client()

    # ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ Langfuseë¡œ íŠ¸ë ˆì´ì‹±
    with trace_operation(
        name="summary_vectordb_build",
        metadata={
            "force_recreate": force_recreate,
            "limit": limit,
            "collection_name": collection_name,
            "source_collection": source_collection
        }
    ) as trace:

        # 1. Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        print("\nğŸ“¦ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
        qdrant_client = QdrantClient(path=QDRANT_PATH)

        # 2. Mixed ì»¬ë ‰ì…˜ í™•ì¸
        print(f"\nğŸ“¥ Mixed ì»¬ë ‰ì…˜ í™•ì¸ ì¤‘: {source_collection}")
        try:
            source_info = qdrant_client.get_collection(source_collection)
            print(f"  âœ“ Mixed ì»¬ë ‰ì…˜ ë°œê²¬: {source_info.points_count}ê°œ í¬ì¸íŠ¸")
        except Exception as e:
            print(f"âŒ Mixed ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤: {source_collection}")
            print("ë¨¼ì € build_mixed_vectordb.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")
            return

        # 3. Mixed ì»¬ë ‰ì…˜ì—ì„œ ìš”ì•½ë³¸ë§Œ ê°€ì ¸ì˜¤ê¸°
        print(f"\nğŸ“ ìš”ì•½ë³¸ ì¶”ì¶œ ì¤‘...")
        if trace:
            extraction_span = trace.span(name="summary_extraction")

        # ìš”ì•½ë³¸ë§Œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸°
        summary_points = []
        offset = None
        batch_size = 100

        while True:
            results = qdrant_client.scroll(
                collection_name=source_collection,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(
                            key="properties.content_type",
                            match=MatchValue(value="summary")
                        )
                    ]
                ),
                limit=batch_size,
                offset=offset,
                with_payload=True,
                with_vectors=True
            )

            points, offset = results

            if not points:
                break

            summary_points.extend(points)

            if offset is None:
                break

            if limit and len(summary_points) >= limit:
                summary_points = summary_points[:limit]
                break

        if trace:
            extraction_span.end(metadata={"total_summaries": len(summary_points)})

        print(f"  âœ“ {len(summary_points)}ê°œ ìš”ì•½ë³¸ ì¶”ì¶œ ì™„ë£Œ")

        if not summary_points:
            print("âŒ Mixed ì»¬ë ‰ì…˜ì— ìš”ì•½ë³¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            return

        # í†µê³„
        avg_len = sum(len(p.payload.get("text", "")) for p in summary_points) / len(summary_points)
        print(f"  âœ“ í‰ê·  ìš”ì•½ ê¸¸ì´: {avg_len:.1f}ì")

        # 4. Summary ì»¬ë ‰ì…˜ ìƒì„± ë° ì €ì¥
        print(f"\nğŸ’¾ Summary ì»¬ë ‰ì…˜ ì €ì¥ ì¤‘: {collection_name}")
        if trace:
            storage_span = trace.span(name="qdrant_storage")

        # ì„ë² ë”© ì°¨ì› í™•ì¸ (ì²« ë²ˆì§¸ í¬ì¸íŠ¸ì—ì„œ)
        embedding_dimension = len(summary_points[0].vector)

        # ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        init_summary_collection(
            qdrant_client,
            collection_name,
            embedding_dimension,
            recreate=force_recreate
        )

        # í¬ì¸íŠ¸ ë³µì‚¬ (ìƒˆ UUIDë¡œ)
        new_points = []
        for point in summary_points:
            new_point = PointStruct(
                id=str(uuid.uuid4()),  # ìƒˆ ID ìƒì„±
                vector=point.vector,
                payload=point.payload
            )
            new_points.append(new_point)

        # ë°°ì¹˜ë¡œ ì €ì¥
        batch_size = 100
        for i in range(0, len(new_points), batch_size):
            batch = new_points[i:i + batch_size]
            qdrant_client.upsert(
                collection_name=collection_name,
                points=batch
            )

        print(f"  âœ“ {len(new_points)}ê°œ ìš”ì•½ë³¸ ì €ì¥ ì™„ë£Œ")

        if trace:
            storage_span.end()

        # 5. ê²€ì¦
        print("\nğŸ” ì €ì¥ ê²€ì¦...")
        collection_info = qdrant_client.get_collection(collection_name)
        print(f"  âœ“ ì €ì¥ëœ í¬ì¸íŠ¸ ìˆ˜: {collection_info.points_count}")

        print("\n" + "=" * 60)
        print("ğŸ‰ S11: Summary-Level Vector DB êµ¬ì¶• ì™„ë£Œ!")
        print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {collection_name}")
        print(f"ğŸ“¥ ì†ŒìŠ¤: {source_collection} (ìš”ì•½ë³¸ë§Œ)")
        print(f"ğŸ“Š ì´ ì²­í¬ ìˆ˜: {len(summary_points)}")
        print(f"ğŸ“ í‰ê·  ìš”ì•½ ê¸¸ì´: {avg_len:.1f}ì")
        print("=" * 60)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="S11: Summary-Level Vector DB êµ¬ì¶• (Mixed ìš”ì•½ë³¸ ì¬ì‚¬ìš©)")
    parser.add_argument("--force", action="store_true", help="ì „ì²´ ì¬ìƒì„±")
    parser.add_argument("--limit", type=int, default=None, help="ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜ ì œí•œ")
    parser.add_argument("--collection", type=str, default="notion_summary", help="íƒ€ê²Ÿ ì»¬ë ‰ì…˜ ì´ë¦„")
    parser.add_argument("--source", type=str, default="notion_mixed", help="ì†ŒìŠ¤ Mixed ì»¬ë ‰ì…˜ ì´ë¦„")

    args = parser.parse_args()

    main(
        force_recreate=args.force,
        limit=args.limit,
        collection_name=args.collection,
        source_collection=args.source
    )
