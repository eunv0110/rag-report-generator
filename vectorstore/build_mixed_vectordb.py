#!/usr/bin/env python3
"""S12: Mixed Retrieval Vector DB êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ (ìš”ì•½+ì›ë¬¸ í˜¼í•©)"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from config.settings import *
from models.embeddings.factory import get_embedder
from models.vision.factory import get_vision_model
from core.chunker import process_page_data
from utils.file_utils import load_json
from utils.langfuse_utils import get_langfuse_client, trace_operation
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
import uuid
from tqdm import tqdm


def init_mixed_collection(
    client: QdrantClient,
    collection_name: str,
    dimension: int,
    recreate: bool = False
):
    """
    Mixed Vector DBìš© Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™”

    Args:
        client: Qdrant í´ë¼ì´ì–¸íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        dimension: ë²¡í„° ì°¨ì›
        recreate: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„± ì—¬ë¶€
    """
    if recreate:
        try:
            client.delete_collection(collection_name)
            print(f"  âœ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ: {collection_name}")
        except:
            pass

    # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    collections = [col.name for col in client.get_collections().collections]

    if collection_name not in collections:
        client.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(
                size=dimension,
                distance=Distance.COSINE
            )
        )
        print(f"  âœ“ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
    else:
        print(f"  âœ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚¬ìš©: {collection_name}")


def summarize_chunk(chunk_text: str, llm, max_length: int = 200) -> str:
    """
    ë‹¨ì¼ ì²­í¬ë¥¼ ìš”ì•½

    Args:
        chunk_text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        llm: LLM ëª¨ë¸
        max_length: ìµœëŒ€ ìš”ì•½ ê¸¸ì´ (ì)

    Returns:
        ìš”ì•½ëœ í…ìŠ¤íŠ¸
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ {length}ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”.

ìš”ì•½ ì‹œ ì£¼ì˜ì‚¬í•­:
- ì¤‘ìš”í•œ í‚¤ì›Œë“œì™€ ê°œë…ì€ ë°˜ë“œì‹œ í¬í•¨
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë‚ ì§œ, ì´ë¦„ ë“±ì€ ê°€ëŠ¥í•œ ë³´ì¡´
- í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
- ë¶ˆí•„ìš”í•œ ë¶€ì—° ì„¤ëª… ì œê±°"""),
        ("user", "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n\n{text}")
    ])

    chain = prompt | llm
    result = chain.invoke({"text": chunk_text, "length": max_length})

    return result.content.strip()


def store_mixed_to_qdrant(
    chunks,
    summaries: list,
    summary_embeddings: list,
    original_embeddings: list,
    client: QdrantClient,
    collection_name: str
):
    """
    ìš”ì•½ë³¸ê³¼ ì›ë¬¸ì„ ëª¨ë‘ Qdrantì— ì €ì¥ (ë³„ë„ í¬ì¸íŠ¸ë¡œ)

    Args:
        chunks: ì›ë³¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        summaries: ìš”ì•½ë³¸ ë¦¬ìŠ¤íŠ¸
        summary_embeddings: ìš”ì•½ë³¸ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸
        original_embeddings: ì›ë³¸ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸
        client: Qdrant í´ë¼ì´ì–¸íŠ¸
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
    """
    points = []

    for chunk, summary, summary_emb, original_emb in zip(chunks, summaries, summary_embeddings, original_embeddings):
        # ê³µí†µ ë©”íƒ€ë°ì´í„°
        base_metadata = {
            "page_id": chunk.page_id,
            "page_title": chunk.page_title,
            "section_title": chunk.section_title,
            "section_path": chunk.section_path,
            "has_image": chunk.has_image,
            "image_descriptions": chunk.image_descriptions,
        }

        # 1. ìš”ì•½ë³¸ í¬ì¸íŠ¸
        summary_payload = {
            **base_metadata,
            "chunk_id": str(uuid.uuid4()),
            "text": summary,
            "combined_text": summary,
            "original_text": chunk.combined_text,
            "properties": {
                "content_type": "summary",
                "summary_length": len(summary),
                "original_length": len(chunk.combined_text)
            }
        }

        summary_point = PointStruct(
            id=str(uuid.uuid4()),
            vector=summary_emb.tolist() if hasattr(summary_emb, 'tolist') else summary_emb,
            payload=summary_payload
        )
        points.append(summary_point)

        # 2. ì›ë¬¸ í¬ì¸íŠ¸
        original_payload = {
            **base_metadata,
            "chunk_id": str(uuid.uuid4()),
            "text": chunk.combined_text,
            "combined_text": chunk.combined_text,
            "summary_text": summary,
            "properties": {
                "content_type": "original",
                "original_length": len(chunk.combined_text),
                "summary_length": len(summary)
            }
        }

        original_point = PointStruct(
            id=str(uuid.uuid4()),
            vector=original_emb.tolist() if hasattr(original_emb, 'tolist') else original_emb,
            payload=original_payload
        )
        points.append(original_point)

    # ë°°ì¹˜ë¡œ ì €ì¥
    batch_size = 100
    for i in range(0, len(points), batch_size):
        batch = points[i:i + batch_size]
        client.upsert(
            collection_name=collection_name,
            points=batch
        )

    print(f"  âœ“ {len(chunks)}ê°œ ì²­í¬ â†’ {len(points)}ê°œ í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ (ìš”ì•½+ì›ë¬¸)")


def main(
    force_recreate: bool = False,
    limit: int = None,
    collection_name: str = "notion_mixed",
    summary_length: int = 200
):
    """
    S12: Mixed Retrieval Vector DB êµ¬ì¶• ë©”ì¸ í•¨ìˆ˜

    Args:
        force_recreate: Trueë©´ ì „ì²´ ì¬ìƒì„±
        limit: ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
        collection_name: ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„
        summary_length: ìš”ì•½ ìµœëŒ€ ê¸¸ì´ (ì)
    """
    print("=" * 60)
    print("ğŸ”€ S12: Mixed Retrieval Vector DB êµ¬ì¶• ì‹œì‘")
    print("   (ìš”ì•½+ì›ë¬¸ í˜¼í•© - ê· í˜•í˜•)")
    if limit:
        print(f"ğŸ“Š ì œí•œ: {limit}ê°œ í˜ì´ì§€ë§Œ ì²˜ë¦¬")
    print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {collection_name}")
    print(f"âœ‚ï¸ ìš”ì•½ ê¸¸ì´: {summary_length}ì")
    print("=" * 60)

    # Langfuse ì´ˆê¸°í™”
    get_langfuse_client()

    # ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ Langfuseë¡œ íŠ¸ë ˆì´ì‹±
    with trace_operation(
        name="mixed_vectordb_build",
        metadata={
            "force_recreate": force_recreate,
            "limit": limit,
            "collection_name": collection_name,
            "summary_length": summary_length
        }
    ) as trace:

        data_file = DATA_DIR / "notion_data.json"

        # 1. ëª¨ë¸ ì´ˆê¸°í™”
        print("\nğŸ“¦ ëª¨ë¸ ë¡œë”©...")
        if trace:
            model_span = trace.span(name="model_initialization")

        embedder = get_embedder()
        vision_model = get_vision_model()
        llm = init_chat_model("azure_ai:gpt-5.1", temperature=0.1)
        qdrant_client = QdrantClient(path=QDRANT_PATH)

        if trace:
            model_span.end()

        # 2. ë°ì´í„° ë¡œë“œ
        print("\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
        if not data_file.exists():
            print("âŒ notion_data.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            print("ë¨¼ì € build_vectordb.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            return

        all_data = load_json(str(data_file))
        pages_to_process = all_data[:limit] if limit else all_data
        print(f"  âœ“ {len(pages_to_process)}ê°œ í˜ì´ì§€ ë¡œë“œ")

        # 3. í˜ì´ì§€ë³„ë¡œ ì²­í¬ ìƒì„±
        print("\nâœ‚ï¸ ì²­í‚¹...")
        if trace:
            chunking_span = trace.span(name="chunking")

        all_chunks = []
        for page in tqdm(pages_to_process, desc="ì²­í‚¹"):
            chunks = process_page_data(page, embedder, vision_model)
            all_chunks.extend(chunks)

        if trace:
            chunking_span.end(metadata={"total_chunks": len(all_chunks)})

        print(f"  âœ“ ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")

        if not all_chunks:
            print("âŒ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return

        # 4. ì²­í¬ ìš”ì•½ ìƒì„±
        print(f"\nğŸ“ ì²­í¬ ìš”ì•½ ìƒì„± ì¤‘ ({summary_length}ì ì´ë‚´)...")
        if trace:
            summarization_span = trace.span(name="summarization")

        summaries = []
        for chunk in tqdm(all_chunks, desc="ìš”ì•½"):
            try:
                summary = summarize_chunk(chunk.combined_text, llm, summary_length)
                summaries.append(summary)
            except Exception as e:
                print(f"  âš  ìš”ì•½ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {str(e)[:50]}...")
                # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì›ë³¸ì˜ ì²˜ìŒ ë¶€ë¶„ ì‚¬ìš©
                summaries.append(chunk.combined_text[:summary_length])

        if trace:
            summarization_span.end(metadata={
                "total_summaries": len(summaries),
                "avg_summary_length": sum(len(s) for s in summaries) / len(summaries)
            })

        print(f"  âœ“ {len(summaries)}ê°œ ìš”ì•½ ìƒì„± ì™„ë£Œ")
        avg_summary_len = sum(len(s) for s in summaries) / len(summaries)
        print(f"  âœ“ í‰ê·  ìš”ì•½ ê¸¸ì´: {avg_summary_len:.1f}ì")

        # 5. ì„ë² ë”© ìƒì„± (ìš”ì•½ë³¸ + ì›ë¬¸)
        print(f"\nğŸ”¢ ì„ë² ë”© ìƒì„± ì¤‘ (ìš”ì•½ë³¸ + ì›ë¬¸)...")
        if trace:
            embedding_span = trace.span(name="embedding_generation")

        # ìš”ì•½ë³¸ ì„ë² ë”©
        print("  â†’ ìš”ì•½ë³¸ ì„ë² ë”©...")
        summary_embeddings = embedder.embed_texts(summaries)

        # ì›ë¬¸ ì„ë² ë”©
        print("  â†’ ì›ë¬¸ ì„ë² ë”©...")
        original_texts = [c.combined_text for c in all_chunks]
        original_embeddings = embedder.embed_texts(original_texts)

        if trace:
            embedding_span.end(metadata={
                "num_summary_embeddings": len(summary_embeddings),
                "num_original_embeddings": len(original_embeddings),
                "embedding_dimension": len(summary_embeddings[0])
            })

        print(f"  âœ“ ìš”ì•½ ì„ë² ë”©: {len(summary_embeddings)}ê°œ")
        print(f"  âœ“ ì›ë¬¸ ì„ë² ë”©: {len(original_embeddings)}ê°œ")

        # 6. Qdrantì— ì €ì¥
        print(f"\nğŸ’¾ Qdrant ì €ì¥ ì¤‘ (ì»¬ë ‰ì…˜: {collection_name})...")
        if trace:
            storage_span = trace.span(name="qdrant_storage")

        # ì„ë² ë”© ì°¨ì› í™•ì¸
        embedding_dimension = len(summary_embeddings[0])

        # ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        init_mixed_collection(
            qdrant_client,
            collection_name,
            embedding_dimension,
            recreate=force_recreate
        )

        # ìš”ì•½ë³¸ + ì›ë¬¸ ì €ì¥
        store_mixed_to_qdrant(
            all_chunks,
            summaries,
            summary_embeddings,
            original_embeddings,
            qdrant_client,
            collection_name
        )

        if trace:
            storage_span.end()

        # 7. ê²€ì¦
        print("\nğŸ” ì €ì¥ ê²€ì¦...")
        collection_info = qdrant_client.get_collection(collection_name)
        print(f"  âœ“ ì €ì¥ëœ í¬ì¸íŠ¸ ìˆ˜: {collection_info.points_count}")
        print(f"  âœ“ ì²­í¬ë‹¹ í¬ì¸íŠ¸ ìˆ˜: {collection_info.points_count // len(all_chunks)} (ìš”ì•½+ì›ë¬¸)")

        # í†µê³„
        original_total_len = sum(len(c.combined_text) for c in all_chunks)
        summary_total_len = sum(len(s) for s in summaries)
        avg_original_len = original_total_len / len(all_chunks)

        print("\n" + "=" * 60)
        print("ğŸ‰ S12: Mixed Retrieval Vector DB êµ¬ì¶• ì™„ë£Œ!")
        print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {collection_name}")
        print(f"ğŸ“Š ì´ ì²­í¬ ìˆ˜: {len(all_chunks)}")
        print(f"ğŸ“ ì´ í¬ì¸íŠ¸ ìˆ˜: {collection_info.points_count} (ìš”ì•½ {len(summaries)} + ì›ë¬¸ {len(original_embeddings)})")
        print(f"ğŸ“ í‰ê·  ìš”ì•½ ê¸¸ì´: {avg_summary_len:.1f}ì")
        print(f"ğŸ“„ í‰ê·  ì›ë¬¸ ê¸¸ì´: {avg_original_len:.1f}ì")
        print("=" * 60)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="S12: Mixed Retrieval Vector DB êµ¬ì¶•")
    parser.add_argument("--force", action="store_true", help="ì „ì²´ ì¬ìƒì„±")
    parser.add_argument("--limit", type=int, default=None, help="ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜ ì œí•œ")
    parser.add_argument("--collection", type=str, default="notion_mixed", help="ì»¬ë ‰ì…˜ ì´ë¦„")
    parser.add_argument("--summary-length", type=int, default=600, help="ìš”ì•½ ìµœëŒ€ ê¸¸ì´ (ì)")

    args = parser.parse_args()

    main(
        force_recreate=args.force,
        limit=args.limit,
        collection_name=args.collection,
        summary_length=args.summary_length
    )
