# Langfuse ê¸°ë°˜ ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ê°€ì´ë“œ

## ê°œìš”

LangfuseëŠ” ë‚´ë¶€ì— RAGAS í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•©í•˜ê³  ìˆì–´, ë³„ë„ë¡œ RAGAS íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ì§€ ì•Šì•„ë„ LLM ê¸°ë°˜ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” Langfuse íŠ¸ë ˆì´ì‹±ì„ í™œìš©í•œ ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

## ì£¼ìš” íŠ¹ì§•

- âœ… **RAGAS íŒŒì´í”„ë¼ì¸ ë¶ˆí•„ìš”**: Langfuse ë‚´ì¥ í‰ê°€ ê¸°ëŠ¥ í™œìš©
- âœ… **LLM ê¸°ë°˜ ìë™ í‰ê°€**: Context Precision, Context Recall ë“± ìë™ ì¸¡ì •
- âœ… **Azure AI / OpenRouter ì§€ì›**: OpenAI API ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥
- âœ… **ë¹„êµ ë¶„ì„**: BM25 vs Dense(Vector) ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ
- âœ… **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ì¦‰ì‹œ í™•ì¸

## ë¹ ë¥¸ ì‹œì‘

### 1. í‰ê°€ ë°ì´í„° ì¤€ë¹„

LLM ê¸°ë°˜ ê³ í’ˆì§ˆ QA ë°ì´í„° ìƒì„±:

```bash
python scripts/generate_eval_dataset.py --method llm --num-samples 10 --llm-provider azure
```

### 2. ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰

```bash
python scripts/evaluate_with_langfuse.py --dataset data/evaluation/llm_generated_qa_azure.json --top-k 5
```

### 3. Langfuse ëŒ€ì‹œë³´ë“œ í™•ì¸

https://cloud.langfuse.com ì ‘ì†í•˜ì—¬ ê²°ê³¼ í™•ì¸

## í‰ê°€ ê²°ê³¼ ì˜ˆì‹œ

### ì„±ëŠ¥ ë¹„êµ (10ê°œ ì§ˆë¬¸ ê¸°ì¤€)

| Retriever    | Avg Results | Avg Time (ms) |
|--------------|-------------|---------------|
| BM25         | 5.00        | **10.43**     |
| Dense_Vector | 5.00        | 1120.42       |

### ì£¼ìš” ì¸ì‚¬ì´íŠ¸

1. **ì†ë„**: BM25ê°€ Denseë³´ë‹¤ **100ë°° ì´ìƒ ë¹ ë¦„** (10ms vs 1120ms)
2. **ì •í™•ë„**: Langfuse UIì—ì„œ Context Precision/Recall ìë™ í‰ê°€ ê°€ëŠ¥
3. **í™œìš©**:
   - ì‹¤ì‹œê°„ ì‘ë‹µì´ ì¤‘ìš”í•œ ê²½ìš° â†’ BM25 ì¶”ì²œ
   - ì˜ë¯¸ì  ìœ ì‚¬ë„ê°€ ì¤‘ìš”í•œ ê²½ìš° â†’ Dense ì¶”ì²œ
   - ìµœê³  ì„±ëŠ¥ â†’ í•˜ì´ë¸Œë¦¬ë“œ(BM25 + Dense ì•™ìƒë¸”)

## Langfuseì—ì„œ LLM ê¸°ë°˜ í‰ê°€ ì„¤ì •

### Step 1: Langfuse ëŒ€ì‹œë³´ë“œ ì ‘ì†

1. https://cloud.langfuse.com ë¡œê·¸ì¸
2. í”„ë¡œì íŠ¸ ì„ íƒ

### Step 2: Evaluation LLM ì„¤ì •

#### ì˜µì…˜ A: Azure AI ì‚¬ìš©

1. **Settings** â†’ **Evaluators** ì´ë™
2. **Add Evaluator** í´ë¦­
3. ë‹¤ìŒ ì •ë³´ ì…ë ¥:
   ```
   Provider: Azure OpenAI
   Deployment Name: gpt-5.1
   API Key: [.envì˜ AZURE_AI_CREDENTIAL]
   Endpoint: https://ddokai-resource.services.ai.azure.com/models/
   ```

#### ì˜µì…˜ B: OpenRouter ì‚¬ìš©

1. **Settings** â†’ **Evaluators** ì´ë™
2. **Add Evaluator** í´ë¦­
3. ë‹¤ìŒ ì •ë³´ ì…ë ¥:
   ```
   Provider: OpenAI (Compatible)
   Model: openai/gpt-4o-mini
   API Key: [.envì˜ OPENROUTER_API_KEY]
   Base URL: https://openrouter.ai/api/v1
   ```

### Step 3: ìë™ í‰ê°€ í™œì„±í™”

1. **Evaluations** íƒ­ ì´ë™
2. í‰ê°€ ë©”íŠ¸ë¦­ ì„ íƒ:
   - âœ… Context Precision (ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì˜ ì •ë°€ë„)
   - âœ… Context Recall (ground truth ëŒ€ë¹„ ì¬í˜„ìœ¨)
   - âœ… Faithfulness (ë‹µë³€ì˜ ì¶©ì‹¤ë„)
   - âœ… Answer Relevancy (ë‹µë³€ì˜ ê´€ë ¨ì„±)

3. **Run Evaluation** í´ë¦­

### Step 4: ê²°ê³¼ í™•ì¸

1. **Traces** íƒ­ì—ì„œ ê° ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
2. **Scores** íƒ­ì—ì„œ í‰ê°€ ì ìˆ˜ í™•ì¸
3. **Analytics**ì—ì„œ í†µê³„ ë° íŠ¸ë Œë“œ ë¶„ì„

## ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ í‰ê°€ ë©”íŠ¸ë¦­ ì¶”ê°€

ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •í•˜ì—¬ ì¶”ê°€ ì ìˆ˜ ê¸°ë¡:

```python
# scripts/evaluate_with_langfuse.py ë‚´ë¶€
langfuse.create_score(
    trace_id=event.trace_id,
    name="custom_relevance",
    value=0.95,
    comment="Custom relevance score"
)
```

### ë°°ì¹˜ í‰ê°€

ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— í‰ê°€:

```bash
for dataset in data/evaluation/*.json; do
    python scripts/evaluate_with_langfuse.py --dataset "$dataset"
done
```

### Top-K íŠœë‹

ë‹¤ì–‘í•œ Top-K ê°’ìœ¼ë¡œ ì‹¤í—˜:

```bash
for k in 3 5 10; do
    python scripts/evaluate_with_langfuse.py --dataset data/evaluation/llm_generated_qa_azure.json --top-k $k
done
```

## ì£¼ìš” ëª…ë ¹ì–´ ì •ë¦¬

### í‰ê°€ ë°ì´í„° ìƒì„±

```bash
# ìë™ ìƒì„± (ë¹ ë¦„, API ë¶ˆí•„ìš”)
python scripts/generate_eval_dataset.py --method auto --num-samples 20

# LLM ìƒì„± (ê³ í’ˆì§ˆ, Azure AI)
python scripts/generate_eval_dataset.py --method llm --num-samples 10 --llm-provider azure
```

### ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€

```bash
# ê¸°ë³¸ í‰ê°€
python scripts/evaluate_with_langfuse.py --dataset data/evaluation/llm_generated_qa_azure.json

# Top-K ì¡°ì •
python scripts/evaluate_with_langfuse.py --dataset data/evaluation/llm_generated_qa_azure.json --top-k 10

# BM25 í•œêµ­ì–´ í† í¬ë‚˜ì´ì € ë¹„í™œì„±í™”
python scripts/evaluate_with_langfuse.py --dataset data/evaluation/llm_generated_qa_azure.json --no-korean-tokenizer
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Langfuse ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**: `Authentication error: Langfuse client initialized without public_key`

**í•´ê²°**:
```bash
# .env íŒŒì¼ í™•ì¸
cat .env | grep LANGFUSE

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
echo $LANGFUSE_PUBLIC_KEY
echo $LANGFUSE_SECRET_KEY
```

### 2. í‰ê°€ ë°ì´í„° ì—†ìŒ

**ì¦ìƒ**: `FileNotFoundError: data/evaluation/llm_generated_qa_azure.json`

**í•´ê²°**:
```bash
# í‰ê°€ ë°ì´í„° ìƒì„±
python scripts/generate_eval_dataset.py --method llm --num-samples 10 --llm-provider azure
```

### 3. Azure AI API ì˜¤ë¥˜

**ì¦ìƒ**: `Unavailable model: gpt-4o-mini`

**í•´ê²°**:
- `.env` íŒŒì¼ì—ì„œ ëª¨ë¸ëª…ì„ `gpt-5.1`ë¡œ ë³€ê²½
- Azure AI í¬ë ˆë´ì…œ í™•ì¸

## Langfuse vs RAGAS ì§ì ‘ ì‚¬ìš© ë¹„êµ

| í•­ëª© | Langfuse í†µí•© | RAGAS ì§ì ‘ ì‚¬ìš© |
|------|---------------|-----------------|
| **ì„¤ì • ë³µì¡ë„** | â­ ê°„ë‹¨ (UI ì„¤ì •) | â­â­â­ ë³µì¡ (ì½”ë“œ ì‘ì„±) |
| **LLM ì œê³µì** | Azure AI, OpenRouter ë“± | OpenAI API í•„ìˆ˜ |
| **í‰ê°€ ìë™í™”** | âœ… ìë™ | âŒ ìˆ˜ë™ êµ¬í˜„ í•„ìš” |
| **ì‹œê°í™”** | âœ… ëŒ€ì‹œë³´ë“œ ì œê³µ | âŒ ë³„ë„ êµ¬í˜„ í•„ìš” |
| **ì¶”ì²œ ìƒí™©** | í”„ë¡œë•ì…˜, ì§€ì†ì  ëª¨ë‹ˆí„°ë§ | ì—°êµ¬, ì¼íšŒì„± ì‹¤í—˜ |

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… **í‰ê°€ ë°ì´í„° ìƒì„± ì™„ë£Œ** (10ê°œ LLM ê¸°ë°˜ QA)
2. âœ… **ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ** (BM25 vs Dense)
3. ğŸ”„ **Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ LLM í‰ê°€ ì„¤ì •**
4. ğŸ“Š **Context Precision/Recall ìë™ í‰ê°€ í™•ì¸**
5. ğŸš€ **í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì„±ëŠ¥ í‰ê°€**

## ì°¸ê³  ìë£Œ

- [Langfuse ê³µì‹ ë¬¸ì„œ](https://langfuse.com/docs)
- [RAGAS í‰ê°€ ë©”íŠ¸ë¦­](https://docs.ragas.io/en/latest/concepts/metrics/index.html)
- [ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ](QUICK_START.md)
- [BM25 í‰ê°€ ê°€ì´ë“œ](BM25_EVALUATION_GUIDE.md)
